{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37441e67",
   "metadata": {},
   "source": [
    "# ðŸ““ Notebook 1 â€“ Exploratory Data Analysis (EDA) of Pose Outputs\n",
    "\n",
    "## 1. Introduction & objectives\n",
    "\n",
    "In this notebook, we will explore pose estimation outputs generated with SuperAnimal ModelZoo on 10-minute top-view mouse videos.\n",
    "\n",
    "**Learning goals:**\n",
    "- Understand the structure of .h5 output files\n",
    "- Explore metadata and summary statistics\n",
    "- Visualize likelihoods, trajectories, and skeletons\n",
    "- Detect and correct errors (missing points, jumps)\n",
    "- Compare outputs from clear vs challenging videos\n",
    "- Prepare cleaned data for further analysis\n",
    "  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/LizbethMG-Teaching/pose2behav-book/main/assets/notebook-image1.png\" width=\"50%\">\n",
    "\n",
    "**Narrative**\n",
    "\n",
    "Imagine you are a junior researcher in a neuroscience lab. Your colleague just handed you pose estimation outputs generated with SuperAnimal ModelZoo from 10-minute videos of mice exploring an arena. Before you can ask scientific questions about locomotion, posture, or social behavior, you need to verify the quality of these model predictions. Are all the keypoints tracked reliably? Do some body parts drop out in certain conditions? How does tracking quality differ between a clear video and a more challenging one?\n",
    "\n",
    "In this notebook, you will take the role of a data detective: opening the .h5 pose files, exploring the structure, visualizing likelihoods and trajectories, spotting errors, and applying simple corrections. By the end, you will produce a short â€œquality reportâ€ that prepares you for deeper behavioral analysis in the next notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc44a0e",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Format Inspection\n",
    "\n",
    "ðŸ‘‰ Goal: learn to open .h5 files and understand their structure.\n",
    "- Load one file into a pandas DataFrame\n",
    "- Inspect columns: scorer, bodypart, x, y, likelihood\n",
    "- Count frames and list bodyparts\n",
    "\n",
    "Exercise 1:\n",
    "List all detected bodyparts and classify them as head / body / tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedf984",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === Install helpers (quiet) ===\n",
    "!pip -q install gdown tables\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gdown, pandas as pd, numpy as np\n",
    "\n",
    "# ---- CHANGE ONLY IF YOU WANT A DIFFERENT DESTINATION ----\n",
    "DEST = Path(\"/content/dlc_output.h5\")\n",
    "\n",
    "# ====== INSTRUCTIONS ======\n",
    "# We already set a default FILE_ID for demonstration. In class you will receive your own FILE_ID.\n",
    "# If the instructors give you a different FILE_ID, replace it below and re-run this cell.\n",
    "\n",
    "FILE_ID = \"11zcVPSS4D-JLQQ11hkMbPwmqs-cd6Am2\"  # demo file id (replace when needed)\n",
    "URL = f\"https://drive.google.com/uc?id={FILE_ID}\"\n",
    "\n",
    "print(\"Downloading from Drive...\")\n",
    "_ = gdown.download(URL, str(DEST), quiet=False)\n",
    "\n",
    "# Basic checks\n",
    "assert DEST.exists() and DEST.stat().st_size > 0, \"âŒ Download failed or empty file.\"\n",
    "print(f\"âœ… Downloaded to {DEST} ({DEST.stat().st_size/1_000_000:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb9119",
   "metadata": {},
   "source": [
    "## 3. Metadata & basic summary\n",
    "\n",
    "ðŸ‘‰ Goal: extract key metadata and get a first impression of data quality.\n",
    "- Print frame rate, duration, number of frames\n",
    "- Compute % of missing/low-confidence points per bodypart\n",
    "- Create summary table of likelihoods\n",
    "\n",
    "Exercise 2:\n",
    "Which bodypart is most reliably detected? Which one is least?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d3fbdb",
   "metadata": {},
   "source": [
    "## 4. Likelihood distributions\n",
    "\n",
    "\n",
    "ðŸ‘‰ Goal: visualize the reliability of detections.\n",
    "- Histograms of likelihood per bodypart\n",
    "- Violin plots comparing bodyparts\n",
    "- Fraction of frames below confidence threshold\n",
    "\n",
    "Exercise 3:\n",
    "Compare the tail base vs nose likelihood distributions. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf910071",
   "metadata": {},
   "source": [
    "## 5. Time series inspection\n",
    "\n",
    "ðŸ‘‰ Goal: detect failures and instability across time.\n",
    "- Plot time series of x,y positions for nose (or other keypoints)\n",
    "- Plot likelihood as a function of time\n",
    "\n",
    "Exercise 4:\n",
    "Spot at least two segments where the model clearly failed (likelihood drops)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c58d90",
   "metadata": {},
   "source": [
    "## 6. Spatial distributions\n",
    "\n",
    "ðŸ‘‰ Goal: understand where in the arena each bodypart was detected.\n",
    "- Scatter plot of nose positions\n",
    "- Kernel density estimate heatmap of occupancy\n",
    "- Overlay all bodypart scatter plots\n",
    "\n",
    "Exercise 5:\n",
    "Does the mouse explore the arena uniformly or are there preferences (corners, walls)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc725bc7",
   "metadata": {},
   "source": [
    "## 7. Visual diagnostics \n",
    "\n",
    "ðŸ‘‰ Goal: overlay skeletons on frames and create animations.\n",
    "- Pick random frames and overlay skeleton on image\n",
    "- Short animation (GIF or video snippet) of 200 frames with skeleton overlay\n",
    "- Compare clear video vs challenging video\n",
    "\n",
    "Exercise 6:\n",
    "Compare skeleton overlays between clear and noisy video. What errors do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181e448",
   "metadata": {},
   "source": [
    "## 8. Outlier & Error Detection\n",
    "\n",
    "ðŸ‘‰ Goal: identify extreme jumps and suspicious frames.\n",
    "- Compute frame-to-frame displacement for each keypoint\n",
    "- Histogram of displacements; flag outliers\n",
    "- Mark â€œbad framesâ€ with low likelihood or jumps\n",
    "\n",
    "Exercise 7:\n",
    "How many frames of the tail tip exceed a jump threshold of 30 pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ac53f",
   "metadata": {},
   "source": [
    "9. Filtering & Correction\n",
    "\n",
    "ðŸ‘‰ Goal: correct noisy or missing data.\n",
    "- Apply interpolation to missing points\n",
    "- Apply smoothing (rolling median or spline)\n",
    "- Compare raw vs corrected trajectories\n",
    "\n",
    "Exercise 8:\n",
    "Apply interpolation to ear-left trajectory and plot before vs after."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c0f5e9",
   "metadata": {},
   "source": [
    "10. Comparative Analysis (Clear vs Noisy Video)\n",
    "\n",
    "ðŸ‘‰ Goal: see how conditions affect pose quality.\n",
    "- Load outputs from two videos: one clear, one dark/low contrast\n",
    "- Create summary table: % of low-confidence frames per bodypart\n",
    "- Violin plots comparing likelihood distributions\n",
    "\n",
    "Exercise 9:\n",
    "Which video shows more missingness for the nose keypoint? Why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1634b39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Install helpers (quiet)\n",
    "!pip -q install gdown tables\n",
    "\n",
    "import gdown, os, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ðŸ‘‡ Replace with your real Google Drive FILE ID (not the whole link!)\n",
    "FILE_ID = \"11zcVPSS4D-JLQQ11hkMbPwmqs-cd6Am2\"\n",
    "\n",
    "# Build a direct-download URL for gdown\n",
    "URL = f\"https://drive.google.com/uc?id={FILE_ID}\"\n",
    "\n",
    "DEST = Path(\"/content/dlc_output.h5\")\n",
    "print(\"Downloading from Drive...\")\n",
    "gdown.download(URL, str(DEST), quiet=False)\n",
    "\n",
    "# Quick sanity check\n",
    "assert DEST.exists() and DEST.stat().st_size > 0, \"Download failed or empty file.\"\n",
    "print(f\"âœ… Downloaded to {DEST} ({DEST.stat().st_size/1_000_000:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f8c56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# DeepLabCut H5 often stores under keys like 'df_with_missing' or 'df'\n",
    "# We'll try common keys, and fall back to listing what's available.\n",
    "\n",
    "def load_dlc_h5(path: Path):\n",
    "    try:\n",
    "        # Try default (let pandas pick)\n",
    "        return pd.read_hdf(path)\n",
    "    except (KeyError, ValueError):\n",
    "        # Inspect keys and try common ones\n",
    "        with pd.HDFStore(path, mode=\"r\") as store:\n",
    "            keys = [k.strip(\"/\") for k in store.keys()]\n",
    "        print(\"Available keys in H5:\", keys)\n",
    "        for k in [\"df_with_missing\", \"df\", \"pose\", \"table\"]:\n",
    "            if k in keys:\n",
    "                return pd.read_hdf(path, key=k)\n",
    "        # Last resort: first key\n",
    "        if keys:\n",
    "            return pd.read_hdf(path, key=keys[0])\n",
    "        raise RuntimeError(\"No readable tables found in this H5.\")\n",
    "\n",
    "df = load_dlc_h5(DEST)\n",
    "print(\"âœ… Loaded H5 into DataFrame:\", df.shape)\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b1939",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# DLC H5 columns are often a MultiIndex: (scorer, bodypart, coord)\n",
    "if isinstance(df.columns, pd.MultiIndex):\n",
    "    df.columns = [\"{}/{}/{}\".format(*lvl) for lvl in df.columns]\n",
    "print(\"Columns (first 10):\")\n",
    "print(df.columns[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4a8dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try to find any '/x' and matching '/y' columns\n",
    "xcols = [c for c in df.columns if c.endswith(\"/x\")]\n",
    "assert len(xcols) > 0, \"Couldn't find any '/x' columns. Inspect df.columns.\"\n",
    "xcol = xcols[0]\n",
    "ycol = xcol[:-2] + \"/y\"\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df[xcol].values, -df[ycol].values)  # invert y for display\n",
    "plt.title(f\"Trajectory preview: {xcol.split('/')[1] if '/' in xcol else xcol}\")\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"y (top=up)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8b297",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/LizbethMG-Teaching/pose2behav-book/blob/main/notebooks/EDA.ipynb)]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
