{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37441e67",
   "metadata": {},
   "source": [
    "# üìì Notebook 1 ‚Äì Exploratory Data Analysis (EDA) of Pose Outputs\n",
    "\n",
    "## 1. Introduction & objectives\n",
    "\n",
    "In this notebook, we will explore pose estimation outputs generated with SuperAnimal ModelZoo on 10-minute top-view mouse videos.\n",
    "\n",
    "**Learning goals:**\n",
    "- Understand the structure of .h5 output files\n",
    "- Explore metadata and summary statistics\n",
    "- Visualize likelihoods, trajectories, and skeletons\n",
    "- Detect and correct errors (missing points, jumps)\n",
    "- Compare outputs from clear vs challenging videos\n",
    "- Prepare cleaned data for further analysis\n",
    "  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/LizbethMG-Teaching/pose2behav-book/main/assets/notebook-image1.png\" width=\"50%\">\n",
    "\n",
    "**Narrative**\n",
    "\n",
    "Imagine you are a junior researcher in a neuroscience lab. Your colleague just handed you pose estimation outputs generated with SuperAnimal ModelZoo from 5-minute videos of mice exploring an arena. Before you can ask scientific questions about locomotion, posture, or social behavior, you need to verify the quality of these model predictions. Are all the keypoints tracked reliably? Do some body parts drop out in certain conditions? How does tracking quality differ between a clear video and a more challenging one?\n",
    "\n",
    "In this notebook, you will take the role of a data detective: opening the .h5 pose files, exploring the structure, visualizing likelihoods and trajectories, spotting errors, and applying simple corrections. By the end, you will produce a short ‚Äúquality report‚Äù that prepares you for deeper behavioral analysis in the next notebooks.\n",
    "\n",
    "--- \n",
    "\n",
    "**Instructions**\n",
    "\n",
    "This notebook mixes pre-filled code cells (nothing to change) and coding exercises that you will complete.\n",
    "\n",
    "üëâ Here‚Äôs how to work through it:\n",
    "1. Read carefully each section before running the cells.\n",
    "2.\tWhen a cell requires you to code, you‚Äôll see a TODO comment.\n",
    "3.\tThe TODO will tell you how many lines to write.\n",
    "4.\tWrite your code only between the markers:\n",
    "    \n",
    "```python\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# your code goes here\n",
    "# <<<<<<<<<<<<<<<<<<<\n",
    "```\n",
    "\n",
    "‚úã Do not edit anything outside these markers.\n",
    "\n",
    "‚ö° After finishing the course, feel free to experiment and modify the notebook as you like!\n",
    "\n",
    "‚ú® Example\n",
    "\n",
    "What you will see in the notebook:\n",
    "\n",
    "```python\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# TODO (2 lines): compute the duration of the video and print it \n",
    "# variables: frame_count, fps\n",
    "# YOUR CODE: duration = \n",
    "# YOUR CODE: print(...)\n",
    "# <<<<<<<<<<<<<<<<<<< \n",
    "```\n",
    "\n",
    "What you are expected to write: \n",
    "\n",
    "```python\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# TODO (2 lines): compute the duration of the video and print it \n",
    "# variables: frame_count, fps\n",
    "duration = frame_count / fps\n",
    "print(f\"Duration (s):\", duration)\n",
    "# <<<<<<<<<<<<<<<<<<< \n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc44a0e",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Format Inspection\n",
    "\n",
    "üëâ Goal: learn to open .h5 files and understand their structure.\n",
    "- Load one file into a pandas DataFrame\n",
    "- Inspect columns: scorer, bodypart, x, y, likelihood\n",
    "- Count frames and list bodyparts\n",
    "\n",
    "Exercise 1:\n",
    "List all detected bodyparts and classify them as head / body / tail.\n",
    "\n",
    "**2.1 ‚úÖ Install & Download (prefilled)**\n",
    "\n",
    "üì• Download a dataset file from Google Drive (with gdown), save it locally (path depends on Colab vs local), and verify the download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedf984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5055.53s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: dlc_output.h5\n",
      "Downloading from Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11zcVPSS4D-JLQQ11hkMbPwmqs-cd6Am2\n",
      "To: /Users/lix/Library/CloudStorage/OneDrive-Personnel/3-work/teaching/2025_BehavioralAnalysis/pose2behav-book/notebooks/dlc_output.h5\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:08<00:00, 11.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded to dlc_output.h5 (97.80 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install and import the required libraries:\n",
    "!pip -q install gdown tables\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gdown, pandas as pd, numpy as np, numpy as np\n",
    "\n",
    "\n",
    "# Detect if running in Google Colab\n",
    "if \"COLAB_RELEASE_TAG\" in os.environ or \"COLAB_GPU\" in os.environ:\n",
    "    DEST = Path(\"/content/dlc_output.h5\")\n",
    "else:\n",
    "    DEST = Path(\"dlc_output.h5\")  # save in current folder locally\n",
    "print(\"Saving to:\", DEST)\n",
    "\n",
    "# Select here the expeirment you want to download, comment the others:\n",
    "# Opt 1: Single mouse - arena with bedding\n",
    "# FILE_ID = \n",
    "# Opt 2: Single mouse - arena without clear floor\n",
    "# FILE_ID = \n",
    "# Opt 3: Single mouse - beatbox\n",
    "# FILE_ID = \"11zcVPSS4D-JLQQ11hkMbPwmqs-cd6Am2\"\n",
    "# URL = f\"https://drive.google.com/uc?id={FILE_ID}\"\n",
    "\n",
    "print(\"Downloading from Drive...\")\n",
    "_ = gdown.download(URL, str(DEST), quiet=False)\n",
    "\n",
    "# Basic checks\n",
    "assert DEST.exists() and DEST.stat().st_size > 0, \"‚ùå Download failed or empty file.\"\n",
    "print(f\"‚úÖ Downloaded to {DEST} ({DEST.stat().st_size/1_000_000:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fa87f",
   "metadata": {},
   "source": [
    "**2.2 üë©üèª‚Äçüíª Load the HDF5 into a DataFrame (TODO)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ H5 loaded.\n",
      "‚úÖ Focusing on first animal: animal0\n",
      "Frames: 15053\n",
      "Bodyparts: ['head_midpoint', 'left_ear', 'left_ear_tip', 'left_eye', 'left_hip', 'left_midside', 'left_shoulder', 'mid_back', 'mid_backend', 'mid_backend2', 'mid_backend3', 'mouse_center', 'neck', 'nose', 'right_ear', 'right_ear_tip', 'right_eye', 'right_hip', 'right_midside', 'right_shoulder', 'tail1', 'tail2', 'tail3', 'tail4', 'tail5', 'tail_base', 'tail_end']\n",
      "Coords: ['likelihood', 'x', 'y']\n",
      "\n",
      "Flattened columns (sample): ['nose_x', 'nose_y', 'nose_likelihood', 'left_ear_x', 'left_ear_y', 'left_ear_likelihood', 'right_ear_x', 'right_ear_y', 'right_ear_likelihood']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>nose_likelihood</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>left_ear_y</th>\n",
       "      <th>left_ear_likelihood</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>right_ear_y</th>\n",
       "      <th>right_ear_likelihood</th>\n",
       "      <th>left_ear_tip_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_midside_likelihood</th>\n",
       "      <th>right_hip_x</th>\n",
       "      <th>right_hip_y</th>\n",
       "      <th>right_hip_likelihood</th>\n",
       "      <th>tail_end_x</th>\n",
       "      <th>tail_end_y</th>\n",
       "      <th>tail_end_likelihood</th>\n",
       "      <th>head_midpoint_x</th>\n",
       "      <th>head_midpoint_y</th>\n",
       "      <th>head_midpoint_likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nose_x  nose_y  nose_likelihood  left_ear_x  left_ear_y  \\\n",
       "0    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "1    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "2    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "3    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "4    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "\n",
       "   left_ear_likelihood  right_ear_x  right_ear_y  right_ear_likelihood  \\\n",
       "0                 -1.0         -1.0         -1.0                  -1.0   \n",
       "1                 -1.0         -1.0         -1.0                  -1.0   \n",
       "2                 -1.0         -1.0         -1.0                  -1.0   \n",
       "3                 -1.0         -1.0         -1.0                  -1.0   \n",
       "4                 -1.0         -1.0         -1.0                  -1.0   \n",
       "\n",
       "   left_ear_tip_x  ...  right_midside_likelihood  right_hip_x  right_hip_y  \\\n",
       "0            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "1            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "2            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "3            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "4            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "\n",
       "   right_hip_likelihood  tail_end_x  tail_end_y  tail_end_likelihood  \\\n",
       "0                  -1.0        -1.0        -1.0                 -1.0   \n",
       "1                  -1.0        -1.0        -1.0                 -1.0   \n",
       "2                  -1.0        -1.0        -1.0                 -1.0   \n",
       "3                  -1.0        -1.0        -1.0                 -1.0   \n",
       "4                  -1.0        -1.0        -1.0                 -1.0   \n",
       "\n",
       "   head_midpoint_x  head_midpoint_y  head_midpoint_likelihood  \n",
       "0             -1.0             -1.0                      -1.0  \n",
       "1             -1.0             -1.0                      -1.0  \n",
       "2             -1.0             -1.0                      -1.0  \n",
       "3             -1.0             -1.0                      -1.0  \n",
       "4             -1.0             -1.0                      -1.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Per-bodypart QC for first animal (top 10) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coverage</th>\n",
       "      <th>frac_conf&gt;=0.5</th>\n",
       "      <th>mean_likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th>bodyparts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">superanimal_topviewmouse_snapshot-fasterrcnn_mobilenet_v3_large_fpn-004_snapshot-hrnet_w32-004</th>\n",
       "      <th>right_hip</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.553511</td>\n",
       "      <td>0.760140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_ear</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.537102</td>\n",
       "      <td>0.743324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_ear_tip</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.535973</td>\n",
       "      <td>0.656686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_ear</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.475852</td>\n",
       "      <td>0.657428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nose</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.455590</td>\n",
       "      <td>0.673105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eye</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.444496</td>\n",
       "      <td>0.576161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid_back</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.443832</td>\n",
       "      <td>0.594053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_midside</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.438517</td>\n",
       "      <td>0.609447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eye</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.429084</td>\n",
       "      <td>0.581836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head_midpoint</th>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.419518</td>\n",
       "      <td>0.557033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  coverage  \\\n",
       "scorer                                             bodyparts                 \n",
       "superanimal_topviewmouse_snapshot-fasterrcnn_mo... right_hip      0.628446   \n",
       "                                                   left_ear       0.628446   \n",
       "                                                   left_ear_tip   0.628446   \n",
       "                                                   right_ear      0.628446   \n",
       "                                                   nose           0.628446   \n",
       "                                                   right_eye      0.628446   \n",
       "                                                   mid_back       0.628446   \n",
       "                                                   left_midside   0.628446   \n",
       "                                                   left_eye       0.628446   \n",
       "                                                   head_midpoint  0.628446   \n",
       "\n",
       "                                                                  frac_conf>=0.5  \\\n",
       "scorer                                             bodyparts                       \n",
       "superanimal_topviewmouse_snapshot-fasterrcnn_mo... right_hip            0.553511   \n",
       "                                                   left_ear             0.537102   \n",
       "                                                   left_ear_tip         0.535973   \n",
       "                                                   right_ear            0.475852   \n",
       "                                                   nose                 0.455590   \n",
       "                                                   right_eye            0.444496   \n",
       "                                                   mid_back             0.443832   \n",
       "                                                   left_midside         0.438517   \n",
       "                                                   left_eye             0.429084   \n",
       "                                                   head_midpoint        0.419518   \n",
       "\n",
       "                                                                  mean_likelihood  \n",
       "scorer                                             bodyparts                       \n",
       "superanimal_topviewmouse_snapshot-fasterrcnn_mo... right_hip             0.760140  \n",
       "                                                   left_ear              0.743324  \n",
       "                                                   left_ear_tip          0.656686  \n",
       "                                                   right_ear             0.657428  \n",
       "                                                   nose                  0.673105  \n",
       "                                                   right_eye             0.576161  \n",
       "                                                   mid_back              0.594053  \n",
       "                                                   left_midside          0.609447  \n",
       "                                                   left_eye              0.581836  \n",
       "                                                   head_midpoint         0.557033  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected bodyparts per frame ‚Äî summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    15053.000000\n",
       "mean        16.968046\n",
       "std         13.047374\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%         27.000000\n",
       "75%         27.000000\n",
       "max         27.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nose_x (first 5):\n",
      "0   -1.0\n",
      "1   -1.0\n",
      "2   -1.0\n",
      "3   -1.0\n",
      "4   -1.0\n",
      "Name: nose_x, dtype: float64\n",
      "\n",
      "nose_y (first 5):\n",
      "0   -1.0\n",
      "1   -1.0\n",
      "2   -1.0\n",
      "3   -1.0\n",
      "4   -1.0\n",
      "Name: nose_y, dtype: float64\n",
      "\n",
      "nose_likelihood (first 5):\n",
      "0   -1.0\n",
      "1   -1.0\n",
      "2   -1.0\n",
      "3   -1.0\n",
      "4   -1.0\n",
      "Name: nose_likelihood, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the HDF5 pose output into a pandas DataFrame.\n",
    "# TODO: verify the file contains a DataFrame (one line)\n",
    "import numpy as np\n",
    "\n",
    "def read_pose_h5(path: Path) -> pd.DataFrame:\n",
    "    for key in (\"df_with_missing\", \"df\", \"tracks\", \"pose\"):\n",
    "        try:\n",
    "            return pd.read_hdf(path, key=key)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "    return pd.read_hdf(path)\n",
    "\n",
    "df = read_pose_h5(DEST)\n",
    "\n",
    "# Basic sanity check\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# TODO (1 line): Check that the DataFrame \"df\" has at least 1 row.\n",
    "# Clue: ( assert <logical statement>, ‚Äúmessage to return if assertion fails‚Äù )\n",
    "#   If the file was loaded but empty (no rows), this condition is False.\n",
    "#   If condition is True, nothing happens, code continues.\n",
    "\n",
    "assert df.shape[0] > 0, \"Empty DataFrame after loading. Check file.\"\n",
    "# <<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "print(\"‚úÖ H5 loaded.\")\n",
    "\n",
    "# 1) Pick the FIRST animal label in the H5 (usually 'animal0')\n",
    "first_animal = df.columns.get_level_values('individuals').unique()[0]\n",
    "A = df.xs(first_animal, axis=1, level='individuals')   # columns: (scorer, bodyparts, coords)\n",
    "\n",
    "print(f\"‚úÖ Focusing on first animal: {first_animal}\")\n",
    "print(\"Frames:\", df.shape[0])\n",
    "print(\"Bodyparts:\", list(A.columns.levels[1]))\n",
    "print(\"Coords:\", list(A.columns.levels[2]))\n",
    "\n",
    "# 2) Flatten columns for easier use: \"nose_x\", \"nose_y\", \"nose_likelihood\", ...\n",
    "df_flat = A.copy()\n",
    "df_flat.columns = [f\"{bp}_{coord}\" for _, bp, coord in df_flat.columns]\n",
    "print(\"\\nFlattened columns (sample):\", df_flat.columns[:9].tolist())\n",
    "display(df_flat.head())\n",
    "\n",
    "# 3) Likelihood-based QC per bodypart (H5 only)\n",
    "#    SuperAnimal often uses -1 for ‚Äúno detection‚Äù. Convert <0 to NaN before stats.\n",
    "L = A.xs('likelihood', axis=1, level='coords')      # (frames, bodyparts)\n",
    "L_valid = L.where(L >= 0)                            # drop -1 sentinel -> NaN\n",
    "\n",
    "per_bp = pd.DataFrame({\n",
    "    'coverage'        : L_valid.notna().mean(axis=0),          # fraction of frames with any detection\n",
    "    'frac_conf>=0.5'  : (L_valid >= 0.5).mean(axis=0),         # fraction of frames confidently detected\n",
    "    'mean_likelihood' : L_valid.mean(axis=0),                  # average likelihood (ignoring -1)\n",
    "}).sort_values(['frac_conf>=0.5','coverage','mean_likelihood'], ascending=False)\n",
    "per_bp.index.name = 'bodypart'\n",
    "\n",
    "print(\"\\n=== Per-bodypart QC for first animal (top 10) ===\")\n",
    "display(per_bp.head(10))\n",
    "\n",
    "# 4) Frame-level quick view (how many bodyparts detected per frame)\n",
    "detected_per_frame = L_valid.notna().sum(axis=1)  # integer count per frame\n",
    "print(\"\\nDetected bodyparts per frame ‚Äî summary:\")\n",
    "display(detected_per_frame.describe())\n",
    "\n",
    "# 5) Access helpers (examples)\n",
    "#    - Single series: nose_x / nose_y / nose_likelihood\n",
    "#    - First 5 rows shown for demonstration\n",
    "for name in [\"nose_x\", \"nose_y\", \"nose_likelihood\"]:\n",
    "    if name in df_flat.columns:\n",
    "        print(f\"\\n{name} (first 5):\")\n",
    "        print(df_flat[name].head())\n",
    "    else:\n",
    "        print(f\"\\n{name} not found in columns (check bodypart names).\")\n",
    "\n",
    "# 6) Sanity checks students can discuss:\n",
    "#    - If many bodyparts show coverage ‚âà 0 and mean_likelihood ‚âà NaN,\n",
    "#      the animal may not have been detected (or wrong slot chosen).\n",
    "low_cov = (per_bp['coverage'] < 0.05).mean()\n",
    "if low_cov == 1.0:\n",
    "    print(\"\\n‚ö†Ô∏è All bodyparts have very low coverage (<5%). \"\n",
    "          \"This first animal slot may be empty in this file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16887568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ H5 loaded.\n",
      "Shape: (15053, 810)\n",
      "Column level names: ['scorer', 'individuals', 'bodyparts', 'coords']\n",
      "First 6 columns: MultiIndex([('superanimal_topviewmouse_snapshot-fasterrcnn_mobilenet_v3_large_fpn-004_snapshot-hrnet_w32-004', ...),\n",
      "            ('superanimal_topviewmouse_snapshot-fasterrcnn_mobilenet_v3_large_fpn-004_snapshot-hrnet_w32-004', ...),\n",
      "            ('superanimal_topviewmouse_snapshot-fasterrcnn_mobilenet_v3_large_fpn-004_snapshot-hrnet_w32-004', ...),\n",
      "            ('superanimal_topviewmouse_snapshot-fasterrcnn_mobilenet_v3_large_fpn-004_snapshot-hrnet_w32-004', ...),\n",
      "            ('superanimal_topviewmouse_snapshot-fasterrcnn_mobilenet_v3_large_fpn-004_snapshot-hrnet_w32-004', ...),\n",
      "            ('superanimal_topviewmouse_snapshot-fasterrcnn_mobilenet_v3_large_fpn-004_snapshot-hrnet_w32-004', ...)],\n",
      "           names=['scorer', 'individuals', 'bodyparts', 'coords'])\n",
      "\n",
      "=== Active-animal summary (sorted) ===\n",
      "         mean_likelihood  frac_conf>=0.5  mean_xy_variance\n",
      "animal                                                    \n",
      "animal0        -0.053862        0.323467      18495.896882\n",
      "animal1        -0.998368        0.000598      18766.132134\n",
      "animal2        -0.999901        0.000030          0.000000\n",
      "animal3        -1.000000        0.000000               NaN\n",
      "animal4        -1.000000        0.000000               NaN\n",
      "animal5        -1.000000        0.000000               NaN\n",
      "animal6        -1.000000        0.000000               NaN\n",
      "animal7        -1.000000        0.000000               NaN\n",
      "animal8        -1.000000        0.000000               NaN\n",
      "animal9        -1.000000        0.000000               NaN\n",
      "\n",
      "Best animal picked: animal0\n",
      "Flattened view (first rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>nose_likelihood</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>left_ear_y</th>\n",
       "      <th>left_ear_likelihood</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>right_ear_y</th>\n",
       "      <th>right_ear_likelihood</th>\n",
       "      <th>left_ear_tip_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_midside_likelihood</th>\n",
       "      <th>right_hip_x</th>\n",
       "      <th>right_hip_y</th>\n",
       "      <th>right_hip_likelihood</th>\n",
       "      <th>tail_end_x</th>\n",
       "      <th>tail_end_y</th>\n",
       "      <th>tail_end_likelihood</th>\n",
       "      <th>head_midpoint_x</th>\n",
       "      <th>head_midpoint_y</th>\n",
       "      <th>head_midpoint_likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nose_x  nose_y  nose_likelihood  left_ear_x  left_ear_y  \\\n",
       "0    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "1    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "2    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "3    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "4    -1.0    -1.0             -1.0        -1.0        -1.0   \n",
       "\n",
       "   left_ear_likelihood  right_ear_x  right_ear_y  right_ear_likelihood  \\\n",
       "0                 -1.0         -1.0         -1.0                  -1.0   \n",
       "1                 -1.0         -1.0         -1.0                  -1.0   \n",
       "2                 -1.0         -1.0         -1.0                  -1.0   \n",
       "3                 -1.0         -1.0         -1.0                  -1.0   \n",
       "4                 -1.0         -1.0         -1.0                  -1.0   \n",
       "\n",
       "   left_ear_tip_x  ...  right_midside_likelihood  right_hip_x  right_hip_y  \\\n",
       "0            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "1            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "2            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "3            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "4            -1.0  ...                      -1.0         -1.0         -1.0   \n",
       "\n",
       "   right_hip_likelihood  tail_end_x  tail_end_y  tail_end_likelihood  \\\n",
       "0                  -1.0        -1.0        -1.0                 -1.0   \n",
       "1                  -1.0        -1.0        -1.0                 -1.0   \n",
       "2                  -1.0        -1.0        -1.0                 -1.0   \n",
       "3                  -1.0        -1.0        -1.0                 -1.0   \n",
       "4                  -1.0        -1.0        -1.0                 -1.0   \n",
       "\n",
       "   head_midpoint_x  head_midpoint_y  head_midpoint_likelihood  \n",
       "0             -1.0             -1.0                      -1.0  \n",
       "1             -1.0             -1.0                      -1.0  \n",
       "2             -1.0             -1.0                      -1.0  \n",
       "3             -1.0             -1.0                      -1.0  \n",
       "4             -1.0             -1.0                      -1.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Pose H5 loader + active-animal detector (SuperAnimal / DLC multi-animal) ---\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# If you already defined DEST earlier, it will be reused.\n",
    "# Otherwise, set it here explicitly, e.g.:\n",
    "# DEST = Path(\"dlc_output.h5\")\n",
    "\n",
    "# -------------------------\n",
    "# 1) Robust H5 DataFrame loader\n",
    "# -------------------------\n",
    "def read_pose_h5(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a DeepLabCut/SuperAnimal HDF5 pose file as a pandas DataFrame.\n",
    "    Tries common keys; falls back to root.\n",
    "    \"\"\"\n",
    "    preferred = (\"df_with_missing\", \"df\", \"tracks\", \"pose\")\n",
    "    with pd.HDFStore(path, mode='r') as store:\n",
    "        keys = [k.strip('/') for k in store.keys()]\n",
    "    for k in preferred:\n",
    "        if k in keys:\n",
    "            df = pd.read_hdf(path, key=k)\n",
    "            if not isinstance(df, pd.DataFrame):\n",
    "                raise TypeError(f\"H5 key '{k}' did not return a DataFrame.\")\n",
    "            return df\n",
    "    # Fallback: try without key (some exports store a single root)\n",
    "    df = pd.read_hdf(path)\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"H5 did not contain a DataFrame at root.\")\n",
    "    return df\n",
    "\n",
    "# -------------------------\n",
    "# 2) Active-animal detection (robust, uses level NAMES)\n",
    "# -------------------------\n",
    "def detect_active_animals(df: pd.DataFrame, conf_thresh: float = 0.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a per-animal summary with:\n",
    "      - mean_likelihood         : raw mean (often -1.0 for totally missing)\n",
    "      - frac_conf>=thresh       : fraction of points with likelihood >= conf_thresh\n",
    "      - mean_xy_variance        : average variance across x/y (only where detected)\n",
    "    Sorted so the most likely real animal is on top.\n",
    "    \"\"\"\n",
    "    # Expect a 4-level MultiIndex: scorer / individuals / bodyparts / coords\n",
    "    if not isinstance(df.columns, pd.MultiIndex):\n",
    "        raise ValueError(\"Expected MultiIndex columns (scorer/individuals/bodyparts/coords).\")\n",
    "    expected = ['scorer', 'individuals', 'bodyparts', 'coords']\n",
    "    if list(df.columns.names) != expected:\n",
    "        raise ValueError(f\"Unexpected column levels: {df.columns.names} (expected {expected})\")\n",
    "\n",
    "    animals = list(df.columns.levels[df.columns.names.index('individuals')])\n",
    "\n",
    "    idx = pd.IndexSlice  # for clean multi-index slicing with .loc\n",
    "    rows = []\n",
    "    for a in animals:\n",
    "        # Slice one animal using level NAME\n",
    "        A  = df.xs(a, axis=1, level='individuals')\n",
    "\n",
    "        # Likelihoods: (frames, bodyparts) ‚Äì single label is OK with .xs\n",
    "        L  = A.xs('likelihood', axis=1, level='coords')\n",
    "\n",
    "        # Coordinates: (frames, bodyparts*2) ‚Äì multiple labels -> use .loc + IndexSlice\n",
    "        XY = A.loc[:, idx[:, :, ['x', 'y']]]\n",
    "\n",
    "        # 1) Mean likelihood (SuperAnimal often uses -1.0 as \"no detection\")\n",
    "        mean_L = float(L.mean().mean())\n",
    "\n",
    "        # 2) Fraction confident: drop sentinel < 0 first, then threshold\n",
    "        L_valid = L.where(L >= 0)\n",
    "        frac_conf = float((L_valid >= conf_thresh).mean().mean())\n",
    "\n",
    "        # 3) Movement variance only where detected:\n",
    "        # Build a 3-level boolean mask with SAME columns as XY.\n",
    "        det_mask = L_valid.notna()                  # (frames, bodyparts)\n",
    "        # Duplicate for x/y and elevate to 3-level MI with coords at last level\n",
    "        mask3 = pd.concat([det_mask, det_mask], axis=1, keys=['x', 'y'])\n",
    "        # mask3 levels currently ('coords','scorer','bodyparts') ‚Äì reorder to match XY\n",
    "        mask3 = mask3.swaplevel(0, 2, axis=1).swaplevel(0, 1, axis=1)\n",
    "        mask3 = mask3.sort_index(axis=1)\n",
    "\n",
    "        # Align and mask XY\n",
    "        mask3 = mask3.reindex(columns=XY.columns)   # ensure exact alignment\n",
    "        XY_masked = XY.where(mask3)\n",
    "\n",
    "        mov_var = float(XY_masked.var(ddof=0).mean())  # average variance across all x/y cols\n",
    "\n",
    "        rows.append((a, mean_L, frac_conf, mov_var))\n",
    "\n",
    "    out = pd.DataFrame(rows, columns=['animal', 'mean_likelihood', 'frac_conf>=0.5', 'mean_xy_variance'])\n",
    "    out = out.set_index('animal').sort_values(\n",
    "        ['frac_conf>=0.5', 'mean_xy_variance', 'mean_likelihood'],\n",
    "        ascending=False\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# -------------------------\n",
    "# 3) Pick best animal and flatten columns\n",
    "# -------------------------\n",
    "def pick_top_animal(df: pd.DataFrame, conf_thresh: float = 0.5):\n",
    "    \"\"\"\n",
    "    Detects active animals, returns (best_animal_label, flattened_dataframe_for_that_animal, summary).\n",
    "    Flattened columns are like 'nose_x', 'nose_y', 'nose_likelihood'.\n",
    "    \"\"\"\n",
    "    summary = detect_active_animals(df, conf_thresh=conf_thresh)\n",
    "    top = summary.index[0]  # best-ranked animal\n",
    "\n",
    "    # Slice that animal and flatten to 'bodypart_coord' (drop scorer level in names)\n",
    "    A = df.xs(top, axis=1, level='individuals')\n",
    "    A.columns = [f\"{bp}_{coord}\" for _, bp, coord in A.columns]  # (scorer, bodyparts, coords)\n",
    "    return top, A, summary\n",
    "\n",
    "# -------------------------\n",
    "# 4) (Optional) Compute duration if FPS is known\n",
    "# -------------------------\n",
    "def compute_duration_from_df(df: pd.DataFrame, fps: float) -> dict:\n",
    "    \"\"\"\n",
    "    Returns frames, fps, seconds, minutes.\n",
    "    Note: DLC H5 usually doesn't store FPS; you must supply it (e.g., from the source video).\n",
    "    \"\"\"\n",
    "    if fps <= 0:\n",
    "        raise ValueError(\"FPS must be > 0.\")\n",
    "    n_frames = int(df.shape[0])\n",
    "    seconds = n_frames / fps\n",
    "    return {\n",
    "        \"frames\": n_frames,\n",
    "        \"fps\": float(fps),\n",
    "        \"seconds\": float(seconds),\n",
    "        \"minutes\": float(seconds / 60.0),\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# 5) Run\n",
    "# -------------------------\n",
    "df = read_pose_h5(Path(DEST))\n",
    "\n",
    "# Basic sanity check: ensure at least one row\n",
    "assert df.shape[0] > 0, \"Empty DataFrame after loading. Check file.\"\n",
    "\n",
    "print(\"‚úÖ H5 loaded.\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Column level names:\", df.columns.names)\n",
    "print(\"First 6 columns:\", df.columns[:6])\n",
    "\n",
    "# Detect animals and flatten the top one\n",
    "best_animal, df_flat, summary = pick_top_animal(df, conf_thresh=0.5)\n",
    "\n",
    "print(\"\\n=== Active-animal summary (sorted) ===\")\n",
    "print(summary)\n",
    "\n",
    "print(f\"\\nBest animal picked: {best_animal}\")\n",
    "print(\"Flattened view (first rows):\")\n",
    "display(df_flat.head())\n",
    "\n",
    "# Example (optional): if you know FPS, compute duration\n",
    "# duration = compute_duration_from_df(df, fps=30)\n",
    "# print(\"\\nVideo duration estimate:\", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb9119",
   "metadata": {},
   "source": [
    "## 3. Metadata & basic summary\n",
    "\n",
    "üëâ Goal: extract key metadata and get a first impression of data quality.\n",
    "- Print frame rate, duration, number of frames\n",
    "- Compute % of missing/low-confidence points per bodypart\n",
    "- Create summary table of likelihoods\n",
    "\n",
    "Exercise 2:\n",
    "Which bodypart is most reliably detected? Which one is least?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d3fbdb",
   "metadata": {},
   "source": [
    "## 4. Likelihood distributions\n",
    "\n",
    "\n",
    "üëâ Goal: visualize the reliability of detections.\n",
    "- Histograms of likelihood per bodypart\n",
    "- Violin plots comparing bodyparts\n",
    "- Fraction of frames below confidence threshold\n",
    "\n",
    "Exercise 3:\n",
    "Compare the tail base vs nose likelihood distributions. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf910071",
   "metadata": {},
   "source": [
    "## 5. Time series inspection\n",
    "\n",
    "üëâ Goal: detect failures and instability across time.\n",
    "- Plot time series of x,y positions for nose (or other keypoints)\n",
    "- Plot likelihood as a function of time\n",
    "\n",
    "Exercise 4:\n",
    "Spot at least two segments where the model clearly failed (likelihood drops)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c58d90",
   "metadata": {},
   "source": [
    "## 6. Spatial distributions\n",
    "\n",
    "üëâ Goal: understand where in the arena each bodypart was detected.\n",
    "- Scatter plot of nose positions\n",
    "- Kernel density estimate heatmap of occupancy\n",
    "- Overlay all bodypart scatter plots\n",
    "\n",
    "Exercise 5:\n",
    "Does the mouse explore the arena uniformly or are there preferences (corners, walls)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc725bc7",
   "metadata": {},
   "source": [
    "## 7. Visual diagnostics \n",
    "\n",
    "üëâ Goal: overlay skeletons on frames and create animations.\n",
    "- Pick random frames and overlay skeleton on image\n",
    "- Short animation (GIF or video snippet) of 200 frames with skeleton overlay\n",
    "- Compare clear video vs challenging video\n",
    "\n",
    "Exercise 6:\n",
    "Compare skeleton overlays between clear and noisy video. What errors do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181e448",
   "metadata": {},
   "source": [
    "## 8. Outlier & Error Detection\n",
    "\n",
    "üëâ Goal: identify extreme jumps and suspicious frames.\n",
    "- Compute frame-to-frame displacement for each keypoint\n",
    "- Histogram of displacements; flag outliers\n",
    "- Mark ‚Äúbad frames‚Äù with low likelihood or jumps\n",
    "\n",
    "Exercise 7:\n",
    "How many frames of the tail tip exceed a jump threshold of 30 pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ac53f",
   "metadata": {},
   "source": [
    "9. Filtering & Correction\n",
    "\n",
    "üëâ Goal: correct noisy or missing data.\n",
    "- Apply interpolation to missing points\n",
    "- Apply smoothing (rolling median or spline)\n",
    "- Compare raw vs corrected trajectories\n",
    "\n",
    "Exercise 8:\n",
    "Apply interpolation to ear-left trajectory and plot before vs after."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c0f5e9",
   "metadata": {},
   "source": [
    "10. Comparative Analysis (Clear vs Noisy Video)\n",
    "\n",
    "üëâ Goal: see how conditions affect pose quality.\n",
    "- Load outputs from two videos: one clear, one dark/low contrast\n",
    "- Create summary table: % of low-confidence frames per bodypart\n",
    "- Violin plots comparing likelihood distributions\n",
    "\n",
    "Exercise 9:\n",
    "Which video shows more missingness for the nose keypoint? Why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1634b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Install helpers (quiet)\n",
    "!pip -q install gdown tables\n",
    "\n",
    "import gdown, os, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# üëá Replace with your real Google Drive FILE ID (not the whole link!)\n",
    "FILE_ID = \"11zcVPSS4D-JLQQ11hkMbPwmqs-cd6Am2\"\n",
    "\n",
    "# Build a direct-download URL for gdown\n",
    "URL = f\"https://drive.google.com/uc?id={FILE_ID}\"\n",
    "\n",
    "DEST = Path(\"/content/dlc_output.h5\")\n",
    "print(\"Downloading from Drive...\")\n",
    "gdown.download(URL, str(DEST), quiet=False)\n",
    "\n",
    "# Quick sanity check\n",
    "assert DEST.exists() and DEST.stat().st_size > 0, \"Download failed or empty file.\"\n",
    "print(f\"‚úÖ Downloaded to {DEST} ({DEST.stat().st_size/1_000_000:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f8c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLabCut H5 often stores under keys like 'df_with_missing' or 'df'\n",
    "# We'll try common keys, and fall back to listing what's available.\n",
    "\n",
    "def load_dlc_h5(path: Path):\n",
    "    try:\n",
    "        # Try default (let pandas pick)\n",
    "        return pd.read_hdf(path)\n",
    "    except (KeyError, ValueError):\n",
    "        # Inspect keys and try common ones\n",
    "        with pd.HDFStore(path, mode=\"r\") as store:\n",
    "            keys = [k.strip(\"/\") for k in store.keys()]\n",
    "        print(\"Available keys in H5:\", keys)\n",
    "        for k in [\"df_with_missing\", \"df\", \"pose\", \"table\"]:\n",
    "            if k in keys:\n",
    "                return pd.read_hdf(path, key=k)\n",
    "        # Last resort: first key\n",
    "        if keys:\n",
    "            return pd.read_hdf(path, key=keys[0])\n",
    "        raise RuntimeError(\"No readable tables found in this H5.\")\n",
    "\n",
    "df = load_dlc_h5(DEST)\n",
    "print(\"‚úÖ Loaded H5 into DataFrame:\", df.shape)\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b1939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLC H5 columns are often a MultiIndex: (scorer, bodypart, coord)\n",
    "if isinstance(df.columns, pd.MultiIndex):\n",
    "    df.columns = [\"{}/{}/{}\".format(*lvl) for lvl in df.columns]\n",
    "print(\"Columns (first 10):\")\n",
    "print(df.columns[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try to find any '/x' and matching '/y' columns\n",
    "xcols = [c for c in df.columns if c.endswith(\"/x\")]\n",
    "assert len(xcols) > 0, \"Couldn't find any '/x' columns. Inspect df.columns.\"\n",
    "xcol = xcols[0]\n",
    "ycol = xcol[:-2] + \"/y\"\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df[xcol].values, -df[ycol].values)  # invert y for display\n",
    "plt.title(f\"Trajectory preview: {xcol.split('/')[1] if '/' in xcol else xcol}\")\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"y (top=up)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8b297",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/LizbethMG-Teaching/pose2behav-book/blob/main/notebooks/EDA.ipynb)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose2behav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
