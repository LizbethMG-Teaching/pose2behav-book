{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90b1a11",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/LizbethMG-Teaching/pose2behav-book/blob/main/notebooks/EDA.ipynb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37441e67",
   "metadata": {},
   "source": [
    "# üìì Notebook 1 ‚Äì Exploratory Data Analysis (EDA) of Pose Outputs\n",
    "\n",
    "## 1. Introduction & objectives\n",
    "\n",
    "In this notebook, we will explore pose estimation outputs generated with SuperAnimal ModelZoo on a 5-minute top-view mouse video.\n",
    "\n",
    "**Learning goals:**\n",
    "- Understand the structure of .h5 output files\n",
    "- Explore metadata and summary statistics\n",
    "- Visualize likelihoods\n",
    "- Detect and correct errors (missing points, jumps)\n",
    "- Compare outputs from cleaned vs raw data\n",
    "- Prepare cleaned data for further analysis\n",
    "\n",
    "--- \n",
    "**Instructions**\n",
    "\n",
    "This notebook mixes pre-filled code cells (nothing to change) and coding exercises that you will complete.\n",
    "\n",
    "üëâ Here‚Äôs how to work through it:\n",
    "1. Read carefully each section before running the cells.\n",
    "2.\tWhen a cell requires you to code, you‚Äôll see a TODO comment.\n",
    "3.\tThe TODO will tell you how many lines to write.\n",
    "4.\tWrite your code only between the markers:\n",
    "    \n",
    "```python\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# your code goes here\n",
    "# <<<<<<<<<<<<<<<<<<<\n",
    "```\n",
    "\n",
    "‚úã Do not edit anything outside these markers.\n",
    "\n",
    "‚ö° After finishing the course, feel free to experiment and modify the notebook as you like!\n",
    "\n",
    "‚ú® Example\n",
    "\n",
    "What you will see in the notebook:\n",
    "\n",
    "```python\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# TODO (2 lines): compute the duration of the video and print it \n",
    "# variables: frame_count, fps\n",
    "# YOUR CODE: duration = \n",
    "# YOUR CODE: print(...)\n",
    "# <<<<<<<<<<<<<<<<<<< \n",
    "```\n",
    "\n",
    "What you are expected to write: \n",
    "\n",
    "```python\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# TODO (2 lines): compute the duration of the video and print it \n",
    "# variables: frame_count, fps\n",
    "duration = frame_count / fps\n",
    "print(f\"Duration (s):\", duration)\n",
    "# <<<<<<<<<<<<<<<<<<< \n",
    "```\n",
    "---\n",
    "  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/LizbethMG-Teaching/pose2behav-book/main/assets/notebook-image1.png\" width=\"50%\">\n",
    "\n",
    "**Narrative**\n",
    "\n",
    "Imagine you are a junior researcher in a neuroscience lab. Your colleague just handed you pose estimation outputs generated with Deeplabcut ModelZoo from 5-minute videos of a mouse exploring an arena. Before you can ask scientific questions about locomotion, posture, or social behavior, you need to verify the quality of these model predictions. What are the keypoints tracked? Are all the keypoints tracked reliably? Do some body parts drop out in certain conditions? \n",
    "\n",
    "In this notebook, you will take the role of a data detective: opening the .h5 pose files, exploring the structure, visualizing likelihoods and trajectories, spotting errors, and applying simple corrections. By the end, you will produce a short ‚Äúquality report‚Äù that prepares you for deeper behavioral analysis in the next notebooks.\n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc44a0e",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Format Inspection\n",
    "\n",
    "### üéØ Goal: \n",
    "Learn to open a Deeplabcut ModelZoo output file (.h5 format) and understand its structure.\n",
    "We will \n",
    "- Download a sample dataset,\n",
    "- Load it into a pandas DataFrame, and\n",
    "- Inspect its columns (scorer, bodypart, x, y, likelihood).\n",
    "\n",
    "### Background\n",
    "\n",
    "Before we begin, let‚Äôs recall what the main tools do:\n",
    "\n",
    "| **Library**\t| **Purpose in this notebook** |\n",
    "| -------- | ------- |\n",
    "| pandas\t| Handles tabular data using the DataFrame structure (like an Excel table in Python).|\n",
    "| numpy | Efficient numerical operations on arrays (used under the hood by pandas).|\n",
    "| matplotlib / seaborn\t| Visualization libraries for plotting.|\n",
    "| gdown\t| Lets you download files from Google Drive directly into your notebook.|\n",
    "| tables | Allows reading .h5 (HDF5) files ‚Äî the format DeepLabCut uses to save pose estimation results.|\n",
    "\n",
    "### About the .h5 file format\n",
    "\n",
    ".h5 (or HDF5) is a **hierarchical** data format that can store large structured data efficiently. The lastest versions of DeepLabCut Modelzoo saves pose tracking results in this format: each frame contains coordinates (x, y) and confidence (likelihood) for every detected body part.\n",
    "\n",
    "### 2.1 Download data (prefilled)\n",
    "\n",
    "**üìã Instructions:**\n",
    "\n",
    "Run the cell below, it will automatically:\n",
    "\n",
    "- Install the necessary libraries,\n",
    "- Detect if you‚Äôre in Google Colab or on your own computer,\n",
    "- Download a small .h5 dataset from Google Drive, and\n",
    "- Save it in the right place.\n",
    "\n",
    "‚ö†Ô∏è Note: In Google Colab, files are stored temporarily in /content/ (they disappear when the session ends).\n",
    "On your local computer, they are saved in the same folder as your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedf984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PREFILLED CELL: JUST RUN IT ===\n",
    "\n",
    "\n",
    "# Install required libraries\n",
    "!pip -q install gdown tables\n",
    "\n",
    "# ---- Imports ----\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import groupby\n",
    "import re\n",
    "\n",
    "\n",
    "# ---- Detect environment ----\n",
    "if \"COLAB_RELEASE_TAG\" in os.environ or \"COLAB_GPU\" in os.environ:\n",
    "    DEST = Path(\"/content/dlc_output.h5\")   # Google Colab (temporary storage)\n",
    "    print(\"üíª Running in Google Colab\")\n",
    "else:\n",
    "    DEST = Path(\"dlc_output.h5\")            # Local computer\n",
    "    print(\"üñ•Ô∏è Running locally\")\n",
    "\n",
    "print(f\"üìÇ File will be saved to: {DEST}\")\n",
    "\n",
    "# ---- Download dataset from Google Drive ----\n",
    "# Choose one experiment (uncomment the one you want)\n",
    "FILE_ID = \"1JEpAtkANcXLb9Tsg0GrdNxjQTlx3edlk\"  # Example: single mouse, arena without bedding\n",
    "#FILE_ID = \"11zcVPSS4D-JLQQ11hkMbPwmqs-cd6Am2\"  # Example: Single mouse - beatbox\n",
    "URL = f\"https://drive.google.com/uc?id={FILE_ID}\"\n",
    "print(\"‚¨áÔ∏è Downloading dataset...\")\n",
    "gdown.download(URL, str(DEST), quiet=False)\n",
    "\n",
    "# ---- Verify download ----\n",
    "assert DEST.exists() and DEST.stat().st_size > 0, \"‚ùå Download failed or empty file.\"\n",
    "print(f\"‚úÖ Download complete: {DEST} ({DEST.stat().st_size/1_000_000:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d676775a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2 Load the .h5 file into a DataFrame and explore its content\n",
    "\n",
    "Now we‚Äôll open the pose-estimation file you downloaded and load it into a **pandas DataFrame**, the core data structure for tabular data in Python.\n",
    "\n",
    "Each row represents one video frame, and each column contains:\n",
    "\n",
    "- The x and y coordinates of a detected body part, and\n",
    "- A likelihood score (confidence in the detection).\n",
    "\n",
    "Deeplabcut Modelzoo sometimes saves data under different internal keys (\"df_with_missing\", \"df\", \"tracks\", etc.),\n",
    "so we‚Äôll use a helper function that tries all common options automatically.\n",
    "\n",
    "üí° Why we try several keys when loading a .h5 file\n",
    "\n",
    "The HDF5 (.h5) format is a hierarchical container, like a folder system inside a single file.\n",
    "Instead of having just one flat dataset, an .h5 file can hold multiple tables or ‚Äúgroups‚Äù, each stored under a unique key name (like subfolders).\n",
    "\n",
    "In DeepLabCut, the specific key name depends on:\n",
    "\n",
    "- The software version (older vs newer releases),\n",
    "- Whether the dataset was filtered, interpolated, or merged, and\n",
    "- Whether it comes from a multi-animal project or single-animal one.\n",
    "\n",
    "Here are the most common cases:\n",
    "\n",
    "- \"df_with_missing\":\tDefault for most DeepLabCut outputs, includes NaN (missing) values for undetected body parts.\n",
    "- \"df\": Used by some older or custom versions; similar to above but without the explicit ‚Äúmissing‚Äù tag.\n",
    "- \"tracks\": Used for multi-animal tracking projects (tracklets output).\n",
    "- \"pose\": Occasionally used in intermediate DeepLabCut or SuperAnimal outputs.\n",
    "\n",
    "üìã Instructions:\n",
    "\n",
    "To run the cell below to load the dataset into a DataFrame called df, you will need to: \n",
    "\n",
    "1. üß© Complete the **#TODO** line by writing an assertion that checks that df is not empty.\n",
    "- If df has 0 rows, raise an error with a clear message.\n",
    "- If it has data, the notebook should continue without interruption.\n",
    "\n",
    "üí¨ Hint: You can check the number of rows with df.shape[0] or len(df).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HDF5 pose output into a pandas DataFrame.\n",
    "\n",
    "def read_pose_h5(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a DeepLabCut output file (.h5) and returns a pandas DataFrame.\n",
    "    DLC can save results under different internal keys (e.g. 'df', 'tracks'),\n",
    "    so this function tries several known keys until one works.\n",
    "    \"\"\"\n",
    "    for key in (\"df_with_missing\", \"df\", \"tracks\", \"pose\"):\n",
    "        try:\n",
    "            return pd.read_hdf(path, key=key)\n",
    "        except Exception:\n",
    "            pass # Try next possible key if this one doesn't exist\n",
    "        \n",
    "    # If no specific key worked, try default    \n",
    "    return pd.read_hdf(path)\n",
    "\n",
    "# ---- Load the HDF5 pose output into a pandas DataFrame ----\n",
    "df = read_pose_h5(DEST)\n",
    "\n",
    "# ---- Basic sanity check ----\n",
    "\n",
    "# ---- STUDENT TASK ----\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# üß© TODO: Verify that the DataFrame \"df\" has at least one row.\n",
    "# Hint: use an assert statement to ensure the condition is True.\n",
    "# Pseudo-example: ( assert <logical statement>, ‚Äúmessage to return if assertion fails‚Äù )\n",
    "#   If the file was loaded but empty, raise an error.\n",
    "#   If not empty, the notebook will continue silently..\n",
    "# YOUR CODE HERE ‚Üì‚Üì‚Üì : assert ...\n",
    "# assert df...\n",
    "# <<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "\n",
    "# ---- TEACHER TEST ----\n",
    "def test_assertion():\n",
    "    \"\"\"Check that the student's assertion refers to the right variable and logic.\"\"\"\n",
    "    try:\n",
    "        assert isinstance(df, pd.DataFrame), \"df is not a DataFrame\"\n",
    "        assert df.shape[0] > 0, \"DataFrame seems empty\"\n",
    "        print(\"‚úÖ Test passed, correct assertion and valid DataFrame.\")\n",
    "    except AssertionError as e:\n",
    "        print(\"‚ö†Ô∏è Test failed:\", e)\n",
    "\n",
    "test_assertion()\n",
    "\n",
    "\n",
    "print(\"‚úÖ H5 loaded successfully!.\")\n",
    "\n",
    "# Show dataframe info\n",
    "print(\" Data shape (rows, columns):\", df.shape)\n",
    "# Display the first 5 rows as a nice HTML table\n",
    "display(df)  # Display first 5 rows as a formatted HTML table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3412b7",
   "metadata": {},
   "source": [
    "--- \n",
    "### 2.3 - List tracked animals and body parts\n",
    "\n",
    "Now that we‚Äôve loaded the pose data, let‚Äôs explore how it‚Äôs structured inside the DataFrame.\n",
    "DeepLabCut saves the tracking results using a multi-indexed column structure: meaning that each column name has several levels (like folders inside folders).\n",
    "\n",
    "Let‚Äôs list the columns we just saw to answer:  \n",
    "- How many individuals are in the file?  \n",
    "- How many body parts are included, and which ones?\n",
    "\n",
    "üí° Note: Understanding the DataFrame structure\n",
    "\n",
    "In 2.2, when you open the .h5 file with display(df), you might notice that you don‚Äôt see which animal each column belongs to.\n",
    "That‚Äôs because the animal identity (and other metadata like scorer or coordinate type) are stored in multiple levels of column labels called a MultiIndex.\n",
    "\n",
    "Each column is identified by a combination of: scorer, animal, bodypart and coords. Because Jupyter only shows the lowest level by default (x, y, likelihood), the animal name may not appear in the table header even though it‚Äôs stored in the DataFrame.\n",
    "\n",
    "**üìã Instructions:**\n",
    "\n",
    "1. Run the cell below to extract and list all detected individuals and body parts.\n",
    "2. Check how many there are and note their names: this helps you understand what the model was trained to track.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üëâüèº PREFILLED CELL ‚Äî JUST RUN IT\n",
    "\n",
    "# Extract names from the column multi-index\n",
    "animals = df.columns.get_level_values(\"individuals\").unique()\n",
    "bodyparts = df.columns.get_level_values(\"bodyparts\").unique()\n",
    "\n",
    "print(\"Number of animals:\", len(animals))\n",
    "print(\"Animals:\", animals.tolist())\n",
    "print(\"Number of bodyparts:\", len(bodyparts))\n",
    "print(\"Bodyparts:\", bodyparts.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023884a0",
   "metadata": {},
   "source": [
    "**Why do we see 10 animals if the video had only 1 mouse?**\n",
    "\n",
    "When you use a pretrained model from the ModelZoo (for example SuperAnimal), the model is often trained for multi-animal scenes and defines several potential individuals (for example 10). Your `.h5` will then contain columns for `individual_0` to `individual_9`.\n",
    "\n",
    "Even if your video contains only one mouse, the model still outputs those slots. This does not mean it found 10 animals. It simply means the network and configuration allow up to 10.\n",
    "\n",
    "\n",
    "In a **single-mouse experiment**:  \n",
    "- Only one slot (usually `animal0`)carries meaningful coordinates\n",
    "- Unused slots are typically filled with sentinel values like -1 for x, y, and likelihood (or NaNs after cleaning)\n",
    "\n",
    "‚öôÔ∏è If you later train your own DLC model, you can control the number of individuals in  `config.yaml `: \n",
    "\n",
    "\n",
    ":\n",
    "```yaml\n",
    "# Multi-animal\n",
    "individuals:\n",
    "  - animal_0\n",
    "  - animal_1\n",
    "  - animal_2\n",
    "```\n",
    "\n",
    "Or for a single animal: \n",
    "\n",
    "```yaml\n",
    "# Single-animal\n",
    "individuals:\n",
    "  - animal_0\n",
    "```\n",
    "\n",
    "\n",
    "üëâ **Using a ModelZoo model in practice:**Keep the individual with consistently highest confidence and ignore the others.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 - Evaluate tracking quality per animal\n",
    "\n",
    "Goal: in a single-animal video, identify which individual slot corresponds to the real mouse.\n",
    "\n",
    "Note: even in single-animal videos, multi-animal models can occasionally misassign frames to another slot. So we score each slot and pick the best one by combining:\n",
    "\n",
    "- **mean_likelihood:** average detection likelihood over all bodyparts and frames (ignoring negatives). Real animals tend to be high  (‚âà 1) , empty slots tend to be NaN or very low.\n",
    "\n",
    "- **frac_conf**: fraction of detections with likelihood ‚â• threshold (default 0.5). Real animals have a large fraction; empty slots are near zero.\n",
    "\n",
    "- **mean_xy_var:** average variance of x and y over time where detections exist. Real animals move, so variance is non-zero; pure noise can show tiny variance and low confidence.\n",
    "\n",
    "\n",
    "**üìã Instructions:**\n",
    "\n",
    "\n",
    "1. Run the helper cell to define the function `animal_activity_summary`. This function returns a summary table with the 3 metrics described above. \n",
    "2. Run the second cell to compute and inspect the summary table. \n",
    "   \n",
    "A partially empty animal (or a fake animal ) may have just a few noisy detections ‚Üí small variance, but with nearly zero likelihood confidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREFILLED, NO NEED TO CHANGE, JUST RUN THIS CELL\n",
    "# Helper to summarize per-animal signal quality & motion\n",
    "\n",
    "def animal_activity_summary(df: pd.DataFrame, conf_thresh: float = 0.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a small per-animal table with:\n",
    "      - mean_likelihood : mean over all bodyparts/frames (often -1 when unused)\n",
    "      - frac_conf       : fraction of points with likelihood >= conf_thresh (ignores <0)\n",
    "      - mean_xy_var     : average variance of x/y where detections exist\n",
    "    Sorted so the most likely real animal is on top.\n",
    "    \"\"\"\n",
    "    if not isinstance(df.columns, pd.MultiIndex):\n",
    "        raise ValueError(\"Expected MultiIndex columns (scorer/individuals/bodyparts/coords).\")\n",
    "    expected = ['scorer', 'individuals', 'bodyparts', 'coords']\n",
    "    if list(df.columns.names) != expected:\n",
    "        raise ValueError(f\"Unexpected column levels: {df.columns.names} (expected {expected})\")\n",
    "\n",
    "    idx = pd.IndexSlice\n",
    "    animals = df.columns.get_level_values(\"individuals\").unique()\n",
    "\n",
    "    rows = []\n",
    "    for a in animals:\n",
    "        A = df.xs(a, axis=1, level=\"individuals\")\n",
    "\n",
    "        # Likelihoods table: (frames, bodyparts)\n",
    "        L = A.xs(\"likelihood\", axis=1, level=\"coords\")\n",
    "        mean_L = float(L.where(L >= 0).mean().mean())\n",
    "\n",
    "        # Valid (>=0) then fraction above threshold\n",
    "        L_valid = L.where(L >= 0)\n",
    "        frac_conf = float((L_valid >= conf_thresh).mean().mean())\n",
    "\n",
    "        # Build masked XY (only where L is valid) to get motion variance\n",
    "        XY = A.loc[:, idx[:, :, [\"x\", \"y\"]]]  # (frames, bodyparts, coords[x,y])\n",
    "\n",
    "        det_mask = L_valid.notna()  # (frames, bodyparts)\n",
    "        # duplicate mask for x and y, then reorder levels to match XY\n",
    "        mask_xy = pd.concat([det_mask, det_mask], axis=1, keys=[\"x\", \"y\"])\n",
    "        mask_xy = mask_xy.swaplevel(0, 2, axis=1).swaplevel(0, 1, axis=1).sort_index(axis=1)\n",
    "        mask_xy = mask_xy.reindex(columns=XY.columns)\n",
    "\n",
    "        mov_var = float(XY.where(mask_xy).var(ddof=0).mean())\n",
    "\n",
    "        rows.append((a, mean_L, frac_conf, mov_var))\n",
    "\n",
    "    out = (pd.DataFrame(rows, columns=[\"animal\", \"mean_likelihood\", \"frac_conf\", \"mean_xy_var\"])\n",
    "             .set_index(\"animal\")\n",
    "             .sort_values([\"frac_conf\", \"mean_xy_var\", \"mean_likelihood\"], ascending=False))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1924409",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.4.1 - Detect the most likely real animal\n",
    "\n",
    "**Goal**\n",
    "\n",
    "Use the helper animal_activity_summary() to compute a per-animal table of quality metrics, then identify the best candidate. Start with conf_thresh = 0.5.\n",
    "\n",
    "**What you should get**\n",
    "A DataFrame named **summary** indexed by animal id, sorted so that the most plausible real animal is first.\n",
    "\n",
    "**How to read the summary table**\n",
    "\n",
    "What the signals mean\n",
    "\n",
    "- High `mean_xy_var` plus high `frac_conf` ‚Üí likely a real moving animal\n",
    "\n",
    "- Low or NaN `mean_xy_va`r plus low `frac_conf` ‚Üí empty placeholder\n",
    "\n",
    "About the threshold\n",
    "\n",
    "- `frac_conf` uses conf_thresh = 0.5 by default. This is a reasonable starting point, but you can try 0.6 to 0.8 if lighting is good, or 0.3 to 0.4 if detections are sparse.\n",
    "\n",
    "Interpreting a typical top row example\n",
    "\n",
    "- mean_likelihood ‚âà 0.87 ‚Üí strong detections on average\n",
    "- frac_conf ‚âà 0.93 ‚Üí about 93% of points exceed the 0.5 threshold\n",
    "- mean_xy_var ‚âà 32,000 ‚Üí substantial motion over time, consistent with a real animal\n",
    "\n",
    "Conclusion\n",
    "This top animal is the real mouse and should be kept. The remaining animals are placeholders from a multi-animal model configuration.\n",
    "\n",
    "**Caveats to mention**:\n",
    "\n",
    "- mean_xy_var depends on pixel scale, camera FOV, and FPS. Larger arenas or higher resolution inflate variance.\n",
    "- Long immobility periods can lower variance for real animals. Consider checking a time window where movement occurs.\n",
    "- Occlusions and poor lighting can drop frac_conf and mean_likelihood. Adjust conf_thresh if needed.\n",
    "- Camera shake or tracking glitches can inflate variance\n",
    "\n",
    "üìù **Instructions**\n",
    "\n",
    "You will now detect the most likely **real animal** using the helper function defined above.\n",
    "\n",
    "1. üß© Complete the line marked with `# TODO` to use the helper function `animal_activity_summary(f, conf_thresh)` and create a variable called  `summary` to store the result.\n",
    "   1. Start with a confidence threshold `conf_thresh = 0.5`.\n",
    "   2. Run the cell to see the sorted table\n",
    "   3. The quick check at the end will validate your result and print the top animal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREFILLED CELL - COMPLETE THE TODO THEN RUN\n",
    "\n",
    "print(\"\\n=== Detecting the most likely real animal... ===\")\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# üß© TODO: compute the per-animal summary using the helper (1 line). Try conf_thresh=0.5 first.\n",
    "# YOUR CODE (1 line) HERE ‚Üì‚Üì‚Üì : \n",
    "# summary = ...\n",
    "# <<<<<<<<<<<<<<<<<<\n",
    "\n",
    "\n",
    "# --- Display result ---\n",
    "print(\"\\n--- Active-animal summary (sorted) ---\")\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e3660",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.5  Isolate one animal's pose data and prepare it for downstream analysis.\n",
    "\n",
    "Now that you have the per-animal summary, your goal is to **pick the most likely real animal**.\n",
    "\n",
    "üìù **Instructions**\n",
    "\n",
    "1. üß© Complete the line marked with `# TODO`:  from the `summary` DataFrame, select the **index** that corresponds to the most active animal after sorting.  \n",
    "2. Store it in a variable called `best_animal`.   \n",
    "\n",
    "Now that you‚Äôve identified the `best_animal`, the rest fo the code will isolate its pose data as following:\n",
    "\n",
    "1. Slice df to keep only that animal: `.xs(best_animal, axis=1, level=\"individuals\")`\n",
    "2. Drop the `scorer` level if present, then flatten to single-level names like nose_x, paw_likelihood\n",
    "3. Store the result as `df_one`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14290304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREFILLED CELL - COMPLETE THE TODO THEN RUN\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>\n",
    "# üß© TODO: Pick the most likely real animal from the summary index (1 line)\n",
    "# Hint: it's the first row after sorting, so index[0]\n",
    "# YOUR CODE HERE ‚Üì‚Üì‚Üì (1 line) : \n",
    "# best_animal = ...\n",
    "# <<<<<<<<<<<<<<<<<<\n",
    "\n",
    "print(f\"Best animal picked: {best_animal}\")\n",
    "\n",
    "# Slice that animal and flatten columns to 'bodypart_coord' for simple downstream use\n",
    "A = df.xs(best_animal, axis=1, level=\"individuals\")\n",
    "\n",
    "# 2) Drop scorer level if present so that columns are (bodyparts, coords)\n",
    "if \"scorer\" in A.columns.names:\n",
    "    try:\n",
    "        A = A.droplevel(\"scorer\", axis=1)\n",
    "    except Exception:\n",
    "        # If there are multiple scorers, keep the first one explicitly\n",
    "        first_scorer = A.columns.get_level_values(\"scorer\")[0]\n",
    "        A = A.xs(first_scorer, axis=1, level=\"scorer\")\n",
    "\n",
    "# 3) Flatten columns to single level: 'bodypart_coord'\n",
    "if list(A.columns.names) != [\"bodyparts\", \"coords\"]:\n",
    "    raise ValueError(f\"Unexpected column levels after slicing: {A.columns.names}\")\n",
    "A.columns = [f\"{bp}_{coord}\" for bp, coord in A.columns]\n",
    "\n",
    "# 4) Store with a clear name for downstream code\n",
    "df_one = A\n",
    "\n",
    "print(\"Single-animal DataFrame shape:\", df_one.shape)\n",
    "display(df_one.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb9119",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Metadata & basic summary\n",
    "\n",
    "üëâ Goal: extract key metadata and get a first impression of the recording and detection quality.\n",
    "\n",
    "You will compute simple metadata from the single-animal DataFrame and the video frame rate. This gives you quick answers like:\n",
    "- How long is the recording in seconds and minutes\n",
    "- How many frames are available\n",
    "- Later, you will relate this to detection quality per body part\n",
    "\n",
    "Typical questions this helps answer\n",
    "\n",
    "- Which body part is most reliably detected?  \n",
    "- Which one tends to be missing or uncertain?  May cause trouble later (e.g., paws, tail tip).\n",
    "\n",
    "### 3.1 Basic metadata exploration\n",
    "\n",
    "üìù **Instructions**\n",
    "\n",
    "Write small helper functions to compute to compute duration and frame statistics. \n",
    "**What you'll do**\n",
    "\n",
    "1. üß© Complete the line marked with `# TODO` to to calculate the total number of frames and the duration in seconds.\n",
    "2. DLC H5 files usually do not store FPS, so you must provide it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1 Duration helper function\n",
    "\n",
    "def compute_duration_from_df(df: pd.DataFrame, fps: float) -> dict:\n",
    "    \"\"\"\n",
    "    Compute basic duration and frame information.\n",
    "    \n",
    "    Parameters\n",
    "        df : Pose DataFrame (frames √ó features)\n",
    "        fps :Frame rate (must be > 0)\n",
    "    Returns\n",
    "        dict : {\"frames\": int, \"fps\": float, \"seconds\": float, \"minutes\": float}\n",
    "    \n",
    "    Note: DLC H5 files usually don't store FPS; supply it manually.\n",
    "    \"\"\"\n",
    "    if fps <= 0:\n",
    "        raise ValueError(\"FPS must be > 0.\")\n",
    "\n",
    "    # >>>>>>>>>>>>>>>>>>>\n",
    "    # üß© TODO: compute total number of frames\n",
    "    # YOUR CODE HERE ‚Üì‚Üì‚Üì  (1 line): \n",
    "    # n_frames = ...\n",
    "    # üß© TODO: compute duration in seconds (frames / fps)\n",
    "    # YOUR CODE HERE ‚Üì‚Üì‚Üì  (1 line): \n",
    "    # seconds = ...\n",
    "    # <<<<<<<<<<<<<<<<<<    \n",
    "\n",
    "    return {\n",
    "        \"Number of frames\": int(n_frames),\n",
    "        \"fps\": float(fps),\n",
    "        \"Duration in seconds\": float(seconds),\n",
    "        \"Duration in minutes\": float(seconds / 60.0),\n",
    "    }\n",
    "\n",
    "meta = compute_duration_from_df(df_one, fps=30)\n",
    "print(meta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44501d63",
   "metadata": {},
   "source": [
    "### 3.2 Detection reliability\n",
    "\n",
    "üëâ Goal: Quantify how reliable each body part was tracked using its likelihood time series, then summarize that as a small per-bodypart table.\n",
    "\n",
    "What likelihood means here\n",
    "- High values near 1.0 mean the model is confident about that body part in that frame\n",
    "- Low values mean uncertainty, often due to occlusion or confusion\n",
    "- A value of ‚àí1 is a sentinel for ‚Äúno detection‚Äù used by some ModelZoo or DLC exports\n",
    "\n",
    "üìù **Instructions**\n",
    "\n",
    "Write small helper functions to compute  data-quality summaries.\n",
    "\n",
    "1. üß© Complete the line marked with `# TODO` to implement the helper function `qc_summary_from_likelihood` to quantify the reliability of each bodypart‚Äôs tracking and create a **summary table** of likelihoods for each body part\n",
    "   \n",
    "What we will compute per body part\n",
    "- **coverage_%**: percent of frames where there is any valid detection (not NaN after cleaning)\n",
    "- **high_conf_%**: percent of frames with likelihood at or above conf_thresh (default 0.5)\n",
    "- **mean_likelihood**: average likelihood over the session, ignoring invalid frames\n",
    "\n",
    "**Notes**\n",
    "- coverage_% and high_conf_% complement each other. A part can have decent coverage but low high_conf if most frames are weak\n",
    "- We first replace sentinel ‚àí1 by NaN so that invalid frames do not bias the averages\n",
    "- You can try stricter thresholds like 0.6 to 0.8 for well-lit videos, or lower if detections are sparse\n",
    "\n",
    "üß† **Questions**\n",
    "1. Which body parts have the lowest coverage_%? Why might that happen in a top view setup?\n",
    "2. If nose has high_conf_% of 95 while tail_tip has 40, how might this affect downstream features like velocity or orientation?\n",
    "3. How would camera angle, fur color, or arena lighting change these metrics?\n",
    "4. How might motion blur at high speed affect these metrics, and which one most?\n",
    "\n",
    "ü§Ø **Challenging questions**\n",
    "1. Is mean_likelihood an adequate summary when there are long missing segments? Propose one alternative metric.  \n",
    "\t\t\n",
    "2. How would you design a single metric score per body part using coverage_%, high_conf_%, and mean_likelihood? Write the formula and explain it.\n",
    "   \n",
    "3. Would median likelihood be more robust than mean_likelihood here? Why or why not?\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.2 Quality control summary from likelihoods\n",
    "\n",
    "def qc_summary_from_likelihood(df_one: pd.DataFrame, conf_thresh: float = 0.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute per-bodypart detection quality metrics.\n",
    "\n",
    "    Parameters\n",
    "        df_one     : single-animal DataFrame (flattened columns like 'nose_x', 'nose_y', 'nose_likelihood')\n",
    "        conf_thresh: threshold used to count a frame as high-confidence\n",
    "\n",
    "    Returns\n",
    "        DataFrame indexed by body part with columns:\n",
    "          - 'coverage_%'     : percent of frames with any valid detection (not NaN after cleaning)\n",
    "          - 'high_conf_%'    : percent of frames with likelihood >= conf_thresh\n",
    "          - 'mean_likelihood': average likelihood ignoring invalid frames\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select only the likelihood columns (one per body part)\n",
    "    L_raw = df_one.filter(like=\"_likelihood\")\n",
    "\n",
    "    # Replace sentinel -1 by NaN so invalid frames are ignored by mean and fractions\n",
    "    L = L_raw.where(L_raw >= 0)\n",
    "\n",
    "    # Compute stats per bodypart (coverage, high_conf%, mean)\n",
    "    per_bp = pd.DataFrame({\n",
    "        # Percent of frames where a valid likelihood exists\n",
    "        # >>>>>>>>>>>>>>>>>>>\n",
    "        # üß© TODO: What fraction of frames have any valid detection (not all NaN)\n",
    "        # YOUR CODE HERE ‚Üì‚Üì‚Üì (1 line), hint (notna(), mean()):\n",
    "        # \"coverage_%\": L ... # this on is a gift üòâ\n",
    "        \"coverage_%\": L.notna().mean(axis=0) * 100,\n",
    "        \n",
    "        # Percent of frames considered high-confidence at the chosen threshold\n",
    "        # üß© TODO: What fraction of frames have likelihood ‚â• conf_thresh (default 0.5)\n",
    "        # YOUR CODE HERE ‚Üì‚Üì‚Üì (1 line): \n",
    "        # \"high_conf_%\": (L >= conf_thresh) ...\n",
    "        \n",
    "        # Average likelihood across time, ignoring invalid frames\n",
    "        # üß© TODO: Average likelihood, ignoring missing values\n",
    "        # YOUR CODE HERE ‚Üì‚Üì‚Üì (1 line):\n",
    "        # \"mean_likelihood\": ...\n",
    "        # <<<<<<<<<<<<<<<<<< \n",
    "\n",
    "    }).sort_values(\"high_conf_%\", ascending=False)\n",
    "    \n",
    "    return per_bp\n",
    "\n",
    "\n",
    "def plot_likelihood_qc(per_bp: pd.DataFrame, title: str = \"Per-bodypart QC\"):\n",
    "    \"\"\"Bar plot of high-confidence rate per body part. Useful for a quick sanity check.\"\"\"\n",
    "    \n",
    "    # Size scales with number of parts so labels remain readable\n",
    "    fig, ax = plt.subplots(figsize=(max(8, len(per_bp) * 0.4), 4))\n",
    "    \n",
    "    # High-confidence percentage per body part\n",
    "    ax.bar(per_bp.index, per_bp[\"high_conf_%\"],\n",
    "           color=\"#C8A2C8\", edgecolor=\"black\")\n",
    "\n",
    "    ax.set(title=title,\n",
    "           xlabel=\"Bodypart\",\n",
    "           ylabel=\"High-confidence frames (%)\",\n",
    "           ylim=(0, 100))\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.35)\n",
    "\n",
    "    # Rotate labels so they don‚Äôt overlap\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Build the QC table and visualize it\n",
    "qc = qc_summary_from_likelihood(df_one)\n",
    "display(qc)\n",
    "plot_likelihood_qc(qc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf910071",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Time series inspection, looking for \"bad\" frames.\n",
    "\n",
    "üëâ Goal: Detect failures and instability over time so you can map reliability gaps in tracking.\n",
    "\n",
    "What you will do: \n",
    "- Identify strict global failures where every body part has likelihood -1 in a frame\n",
    "- Summarize those failures as consecutive segments with frame indices and human-readable times\n",
    "- Visualize failures on a simple timeline to see if problems are short gaps or long outages\n",
    "\n",
    "How to use this later:\n",
    "\n",
    "- Short gaps (for example fewer than 10 frames) are good candidates for interpolation\n",
    "- Long gaps should remain NaN to flag unreliable periods and avoid fabricating data\n",
    "- With this information you can decide if the video's results are good enough for downstream analysis.\n",
    "\n",
    "\n",
    "üìù **Instructions**\n",
    "\n",
    "1. üß© Complete the line marked with `# TODO` to complete the helper function `list_failure_segments`\n",
    "- Select likelihood columns with `df_one.filter(like=\"_likelihood\")`\n",
    "- Create a 1D boolean vector `fail` that is True where all body parts equal -1\n",
    "2.\tRun the plot helper to visualize failures over time\n",
    "3.\tList the failure segments and note their durations\n",
    "\n",
    "üß† **Questions**\n",
    "1.\tWhat percentage of frames are flagged as global failures on the timeline?\n",
    "2.\tWhat is the duration in seconds of the longest failure segment?\n",
    "\n",
    "ü§Ø **Challenging questions**\n",
    "1. Why might focusing only on -1 miss important low-confidence failures, and how would you extend this detector to include a threshold on likelihood?\n",
    "\n",
    "2. If failures cluster around specific time intervals, what experimental or setup factors could explain this pattern, and how would you test the hypothesis? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ca75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_failure_segments(df_one, fps: float) -> list[tuple[int, int, str, str]]:\n",
    "    \"\"\"\n",
    "    Find consecutive frames where all body parts report likelihood -1.\n",
    "\n",
    "    Returns and prints a list of segments:\n",
    "      (start_frame, end_frame, start_time_str, end_time_str)\n",
    "\n",
    "    Notes\n",
    "      - This is a strict \"global failure\" detector: every body part is -1 in the frame\n",
    "      - Time strings are MM:SS.ss based on the fps you provide\n",
    "    \"\"\"\n",
    "    # >>>>>>>>>>>>>>>>>>>\n",
    "    # üß©  TODO: select likelihood columns only\n",
    "    # use filter and \"_likelihood\"\n",
    "    # YOUR CODE HERE ‚Üì‚Üì‚Üì (1 line):\n",
    "    # L = df_one.filter( ... )\n",
    "    \n",
    "    \n",
    "    # üß©  TODO: build a 1D boolean array: True where all body parts are -1\n",
    "    # Hint: use .eq(-1).all(axis=1).to_numpy() on L\n",
    "    # YOUR CODE HERE ‚Üì‚Üì‚Üì (1 line):\n",
    "    # fail - L...\n",
    "    # <<<<<<<<<<<<<<<<<\n",
    "    \n",
    "    # Find consecutive True segments in fail (where all bodyparts are -1)\n",
    "    segments = []\n",
    "    for k, g in groupby(enumerate(fail), key=lambda x: x[1]):\n",
    "        if k:  # only failing groups\n",
    "            g = list(g)\n",
    "            start = g[0][0]\n",
    "            end = g[-1][0]\n",
    "            # convert frames ‚Üí time (minutes:seconds)\n",
    "            t1, t2 = start / fps, end / fps\n",
    "            m1, s1 = divmod(t1, 60)\n",
    "            m2, s2 = divmod(t2, 60)\n",
    "            start_str = f\"{int(m1):02d}:{s1:05.2f}\"\n",
    "            end_str = f\"{int(m2):02d}:{s2:05.2f}\"\n",
    "            segments.append((start, end, start_str, end_str))\n",
    "\n",
    "    # Pretty print\n",
    "    if not segments:\n",
    "        print(\"‚úÖ No global failure segments detected.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Global tracking failure segments:\")\n",
    "        for i, (s, e, ts, te) in enumerate(segments, 1):\n",
    "            dur = (e - s + 1) / fps\n",
    "            print(f\" {i:>2}. Frames {s}-{e}  ({ts} ‚Üí {te})  [{dur:.2f}s]\")\n",
    "\n",
    "    return segments\n",
    "\n",
    "def plot_global_failure_timeline(df_one, fps: float | None = None, title=\"Global tracking failures\"):\n",
    "    \"\"\"\n",
    "    Shade frames where all body parts have likelihood -1.\n",
    "    If fps is given, the x-axis is seconds. Otherwise it is frames.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Frames where *all* likelihoods are -1\n",
    "    L = df_one.filter(like=\"_likelihood\")\n",
    "    fail = L.eq(-1).all(axis=1).to_numpy()\n",
    "    x = np.arange(len(fail)) if fps is None else np.arange(len(fail)) / float(fps)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 1.8))\n",
    "    # Shade failure regions (lilac)\n",
    "    ax.fill_between(x, 0, 1, where=fail, step=\"post\", alpha=0.7, color=\"#C8A2C8\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    ax.set_xlabel(\"Seconds\" if fps else \"Frames\")\n",
    "    pct = fail.mean() * 100\n",
    "    ax.set_title(f\"{title} ‚Äî {pct:.2f}% frames\")\n",
    "\n",
    "    # Thin grid & tight layout\n",
    "    ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize failures on the timeline\n",
    "plot_global_failure_timeline(df_one, fps=30)  # or fps=None if unknown\n",
    "\n",
    "# List the failure segments with frame indices and times\n",
    "fails = list_failure_segments(df_one, fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f6c2ab",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Outliers\n",
    "\n",
    "üõ∏ When a body part ‚Äúteleports‚Äù between two consecutive frames is one of the most common tracking artefacts in pose estimation, these are called **position or spacial outliers**  üëΩ when a single detection in a frame is far from neighborhood, or **jump spikes** when the distance between consecutive frames is unrealistically large.  To detect those outliers we can compute per-frame speed and compare it to a threshold.\n",
    "\n",
    "As each body part moves at different speeds, for example, a tail could move faster than the center of the body.  \n",
    "\n",
    "Instead of using one fixed ‚Äújump‚Äù threshold for all body parts, we compute an automatic threshold for each one.\n",
    "\n",
    "### STEP 1 :Compute automatic thresholds \n",
    "\n",
    "üëâüèº Goal: In the following cell we will be calculating a robust statistic called the **MAD** = Median Absolute Deviation. \n",
    "\n",
    "It‚Äôs a robust measure of spread (like standard deviation, but it is less sensitive to spikes).\n",
    "\n",
    "    MAD = median(|x_i - median(x)|)\n",
    "\n",
    "Then we set a threshold:\n",
    "\n",
    "    threshold = median(speed) + k x MAD(speed)\n",
    "\n",
    "Typically k = 3 to 4.5. Larger k is more tolerant to spikes.\n",
    "\n",
    "Why this helps$\n",
    "- It adapts automatically to each bodypart‚Äôs natural range of motion.\n",
    "- Different body parts move differently (tail > body center).\n",
    "- Absolute thresholds (e.g., 50 px) can be too strict or too loose.\n",
    "- The MAD rule scales with data spread, so it works well across datasets and behaviors\n",
    "\n",
    "\n",
    "üìù **Instructions**\n",
    "\n",
    "1. üß© Complete the line marked with `# TODO` in the `compute_mad_thresholds` function, use the already computed **med** and **mad** to build the threshold.\n",
    "2.\tKeep the provided mask that ignores frames where likelihood is ‚àí1 or where the previous frame was invalid\n",
    "3.\tPreview the thresholds and notice that fast parts tend to get higher limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a31a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Automatic jump threshold (MAD rule per bodypart) =====\n",
    "# Must be run BEFORE the cleaning pipeline cell\n",
    "\n",
    "def compute_mad_thresholds(df: pd.DataFrame, k: float = 3.5) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute per-bodypart jump threshold using:\n",
    "        threshold = median(speed) + k * MAD(speed)\n",
    "    where speed is the frame-to-frame Euclidean motion in pixels.\n",
    "    Frames with invalid detections are ignored so they do not bias the stats.\n",
    "    \"\"\"\n",
    "    # Get bodypart names from likelihood columns by stripping the suffix\n",
    "    parts = [c.replace(\"_likelihood\", \"\") for c in df.filter(like=\"_likelihood\").columns]\n",
    "    thresholds = {}\n",
    "    \n",
    "    for p in parts:\n",
    "        # Coordinates and likelihood for this body part\n",
    "        x = df[f\"{p}_x\"]; y = df[f\"{p}_y\"]; lik = df[f\"{p}_likelihood\"]\n",
    "\n",
    "        # Build a validity mask:\n",
    "        # - current frame detected (lik != -1)\n",
    "        # - previous frame also detected (needed for a valid speed)\n",
    "        detected_now  = lik.ne(-1)\n",
    "        detected_prev = detected_now.shift(1, fill_value=False)\n",
    "        valid_pair = detected_now & detected_prev\n",
    "\n",
    "        # Frame-to-frame motion speed in pixels per frame\n",
    "        dx = x.diff(); dy = y.diff()\n",
    "        speed = np.hypot(dx, dy).where(valid_pair)\n",
    "\n",
    "        # Robust center and spread of speed\n",
    "        med = float(speed.median(skipna=True) or 0)\n",
    "        mad = float((speed - med).abs().median(skipna=True) or 0)\n",
    "        \n",
    "        # >>>>>>>>>>>>>>>>>>>\n",
    "        # üß© TODO: Compute the per-part threshold using the MAD rule\n",
    "        # YOUR CODE HERE (1 line):\n",
    "        # thr = ...\n",
    "        # <<<<<<<<<<<<<<<<<\n",
    "\n",
    "        # Safety floor to avoid unrealistically tiny thresholds on still parts\n",
    "        thresholds[p] = max(thr, 10.0)  # safety floor (10 px/frame)\n",
    "    return thresholds\n",
    "\n",
    "# ---- compute and preview thresholds ----\n",
    "MAD_K = 3.5\n",
    "auto_thresholds = compute_mad_thresholds(df_one, k=MAD_K)\n",
    "\n",
    "print(f\"Computed automatic thresholds (MAD rule, k={MAD_K}):\")\n",
    "for part, thr in auto_thresholds.items():\n",
    "    print(f\" - {part:>12s}: {thr:6.2f} px/frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13e392",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "From your previous results: \n",
    "\n",
    "Overall your data looks stable with few true jump-spike outliers: coverage is about >95 percent and head/body parts have very high confidence, and the MAD thresholds mostly hitting the 10 px per frame floor suggest small, steady inter-frame motion. The only weak spot is the far tail segments, which show lower confidence more often than big jumps, so they are soft unreliability rather than teleporting points. For downstream work you can keep head and body parts as is, and either down-weight, clean more, or drop tail4 to tail5 depending on whether precise tail motion matters.\n",
    "\n",
    "This is the description of the following steps to clean the data: \n",
    "\n",
    "### STEP 2 :  Identify ‚Äúbad‚Äù frames (mask creation)\n",
    "For each frame and body part, we mark whether the data should be ignored (masked):\n",
    "1.\tMissing detections: frames where likelihood = -1. \n",
    "2.\tJump outliers: frames where the motion speed is above the MAD threshold, and both current and previous frames were valid detections.\n",
    "\n",
    "We also detect global failures, when all body parts are -1 in a frame (the tracker completely lost the animal), as seen in the previous step. \n",
    "\n",
    "These masks are just True/False arrays; they do not change the data yet.\n",
    "\n",
    "### STEP 3: Apply masks (replace invalid values)\n",
    "\n",
    "We apply the masks to the data:\n",
    "- Wherever a mask is True, we replace that (x, y) position with NaN.\n",
    "- This marks the frame as missing, so later we can fill or ignore it.\n",
    "\n",
    "This makes our data cleaner and safer to process, we never trust values from bad detections\n",
    "\n",
    "### Step 4: Interpolate short gaps only\n",
    "\n",
    "After masking, some parts of the trajectory have short gaps.\n",
    "If the gap is shorter than a few frames (for example ‚â§ 10 frames ‚âà 0.3 s at 30 fps), we can interpolate to fill it smoothly.\n",
    "\n",
    "Interpolation estimates the missing points by connecting the last and next valid positions; like ‚Äúdrawing a straight line‚Äù through short missing segments.\n",
    "- The simplest form of interpolation is linear interpolation, however there are more sophisticated methods such as polynomial or spline interpolation.\n",
    "- For longer gaps, we leave them as NaN because we can‚Äôt safely guess the motion.\n",
    "\n",
    "### Step 5:  Light temporal smoothing\n",
    "\n",
    "Even with valid detections, small pixel-level ‚Äújitter‚Äù can appear.\n",
    "We apply a rolling median filter (e.g. window = 5 frames) to smooth sudden tiny oscillations.\n",
    "- It reduces noise without distorting real motion.\n",
    "- Keep the window small so we don‚Äôt blur fast behaviors.\n",
    "\n",
    "### Step 6: Save the cleaned dataset\n",
    "\n",
    "Finally, we save the cleaned DataFrame to an HDF5 file (cleaned_pose.h5).\n",
    "This file keeps the same structure as the original one, but with:\n",
    "- invalid frames replaced by NaN,\n",
    "- short gaps interpolated,\n",
    "- (optional) smoothing applied.\n",
    "\n",
    "You can now use this cleaned dataset for further analysis (behavior classification, trajectory plots, etc.) with much higher reliability.\n",
    "\n",
    "---\n",
    "**üìã Instructions:**\n",
    "1. Read carefully the below description of the pre-processing steps. \n",
    "2. Run the code cell below and verify the output.\n",
    "3. Reflect on how changing the different parameters would change the output:\n",
    "   \n",
    "```\n",
    "    FPS = 30.0\n",
    "    MAX_SPEED_PX_PER_FRAME = 50.0    # used ONLY if a part has no MAD threshold\n",
    "    MAX_SHORT_GAP = 10               # frames; interpolate gaps ‚â§ this\n",
    "    INTERP_METHOD = \"linear\"\n",
    "    APPLY_SMOOTHING = True\n",
    "    SMOOTH_WINDOW = 5                # odd, small (3‚Äì7)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Pose cleaning (only -1 & jumps, with MAD thresholds) =====\n",
    "# - Masks frames with likelihood == -1 and jump spikes (using per-part MAD thresholds)\n",
    "# - Pure / idempotent: no in-place mutations of inputs\n",
    "# -----------------------------\n",
    "# Parameters (tune per dataset)\n",
    "# -----------------------------\n",
    "FPS = 30.0\n",
    "MAX_SPEED_PX_PER_FRAME = 50.0    # used ONLY if a part has no MAD threshold\n",
    "MAX_SHORT_GAP = 10               # frames; interpolate gaps ‚â§ this\n",
    "INTERP_METHOD = \"linear\"\n",
    "APPLY_SMOOTHING = True\n",
    "SMOOTH_WINDOW = 5                # odd, small (3‚Äì7)\n",
    "H5_OUT = \"cleaned_pose.h5\"\n",
    "\n",
    "# -------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------\n",
    "def get_parts(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Extract body-part names from *_likelihood columns.\"\"\"\n",
    "    return [c.replace(\"_likelihood\", \"\") for c in df.filter(like=\"_likelihood\").columns]\n",
    "\n",
    "def build_masks_only_neg1_and_jumps(\n",
    "    df: pd.DataFrame,\n",
    "    max_speed_px_per_frame: float = MAX_SPEED_PX_PER_FRAME,\n",
    "    thresholds: dict | None = None,   # NEW: per-part MAD thresholds\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      global_mask: True where ALL bodyparts have likelihood == -1 in that frame\n",
    "      part_masks: dict[part] -> True where (lik == -1) OR (jump spike when both frames detected)\n",
    "    Uses per-part thresholds if provided; otherwise falls back to fixed max_speed_px_per_frame.\n",
    "    \"\"\"\n",
    "    parts = get_parts(df)\n",
    "\n",
    "    # Global \"-1 for all parts\" mask (per frame)\n",
    "    L = df.filter(like=\"_likelihood\")\n",
    "    global_mask = L.eq(-1).all(axis=1)\n",
    "\n",
    "    # Per-part masks: (-1) OR valid jump spike\n",
    "    part_masks = {}\n",
    "    for p in parts:\n",
    "        lik = df[f\"{p}_likelihood\"]\n",
    "        x   = df[f\"{p}_x\"]\n",
    "        y   = df[f\"{p}_y\"]\n",
    "\n",
    "        # 1) explicit non-detections\n",
    "        neg1 = lik.eq(-1)\n",
    "\n",
    "        # 2) per-frame speed (using previous frame diffs)\n",
    "        dx = x.diff()\n",
    "        dy = y.diff()\n",
    "        speed = np.hypot(dx, dy)\n",
    "\n",
    "        # 3) a \"valid pair\" means both current and previous frames were detected\n",
    "        detected_now  = lik.ne(-1)\n",
    "        detected_prev = detected_now.shift(1, fill_value=False)  # False at first frame\n",
    "        valid_pair = detected_now & detected_prev\n",
    "\n",
    "        # 4) pick threshold: MAD per-part if available, else fixed\n",
    "        thr = thresholds.get(p, max_speed_px_per_frame) if thresholds is not None else max_speed_px_per_frame\n",
    "\n",
    "        # 5) jump outliers only where the pair is valid\n",
    "        jump = (speed > thr) & valid_pair\n",
    "\n",
    "        # final per-part mask\n",
    "        part_masks[p] = neg1 | jump\n",
    "\n",
    "    return global_mask, part_masks\n",
    "\n",
    "def apply_masks(df: pd.DataFrame, global_mask: pd.Series, part_masks: dict) -> pd.DataFrame:\n",
    "    \"\"\"Return a NEW DataFrame with masked (x,y) set to NaN.\"\"\"\n",
    "    out = df.copy(deep=True)\n",
    "    parts = get_parts(out)\n",
    "    # Global: apply to all parts (x,y)\n",
    "    all_xy = [f\"{p}_x\" for p in parts] + [f\"{p}_y\" for p in parts]\n",
    "    out.loc[global_mask, all_xy] = np.nan\n",
    "    # Per-part\n",
    "    for p, m in part_masks.items():\n",
    "        out.loc[m, [f\"{p}_x\", f\"{p}_y\"]] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def interpolate_short_gaps(df: pd.DataFrame, max_gap: int = MAX_SHORT_GAP, method: str = INTERP_METHOD) -> pd.DataFrame:\n",
    "    \"\"\"Return NEW DataFrame with short NaN gaps interpolated.\"\"\"\n",
    "    out = df.copy(deep=True)\n",
    "    for p in get_parts(out):\n",
    "        for axis in (\"_x\", \"_y\"):\n",
    "            col = f\"{p}{axis}\"\n",
    "            # TODO (students): try 'linear' vs 'spline' (order=2) and note differences\n",
    "            out[col] = out[col].interpolate(method=method, limit=max_gap, limit_direction=\"both\")\n",
    "    return out\n",
    "\n",
    "def smooth_positions(df: pd.DataFrame, window: int = SMOOTH_WINDOW) -> pd.DataFrame:\n",
    "    \"\"\"Return NEW DataFrame with rolling-median smoothing (centered).\"\"\"\n",
    "    out = df.copy(deep=True)\n",
    "    for p in get_parts(out):\n",
    "        for axis in (\"_x\", \"_y\"):\n",
    "            col = f\"{p}{axis}\"\n",
    "            out[col] = out[col].rolling(window=window, center=True, min_periods=1).median()\n",
    "    return out\n",
    "\n",
    "def percent_nans(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for p in get_parts(df):\n",
    "        rows.append({\n",
    "            \"part\": p,\n",
    "            \"NaN_x_%\": float(df[f\"{p}_x\"].isna().mean() * 100),\n",
    "            \"NaN_y_%\": float(df[f\"{p}_y\"].isna().mean() * 100),\n",
    "        })\n",
    "    return pd.DataFrame(rows).set_index(\"part\")\n",
    "\n",
    "def speed_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for p in get_parts(df):\n",
    "        x = df[f\"{p}_x\"]; y = df[f\"{p}_y\"]\n",
    "        speed = np.hypot(x.diff(), y.diff())\n",
    "        rows.append({\n",
    "            \"part\": p,\n",
    "            \"speed_median\": float(speed.median(skipna=True) or 0),\n",
    "            \"speed_p95\": float(speed.quantile(0.95)),\n",
    "            \"speed_max\": float(speed.max(skipna=True) or 0),\n",
    "        })\n",
    "    return pd.DataFrame(rows).set_index(\"part\")\n",
    "\n",
    "def quick_mask_report(global_mask: pd.Series, part_masks: dict, thresholds: dict | None = None):\n",
    "    if thresholds is not None:\n",
    "        print(\"Per-part jump thresholds (MAD rule):\")\n",
    "        for p in get_parts(global_mask.to_frame().join(global_mask.to_frame(), how=\"left\", rsuffix=\"_r\")):\n",
    "            if p in thresholds:\n",
    "                print(f\" - {p:>12s}: {thresholds[p]:6.2f} px/frame\")\n",
    "    print(f\"\\nGlobal all-parts == -1: {global_mask.sum()} frames ({100*global_mask.mean():.2f}%)\")\n",
    "    for p, m in part_masks.items():\n",
    "        print(f\"- {p:>12s}: masked {m.sum():5d} frames ({100*m.mean():5.2f}%)\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Pipeline (df_one = your raw predictions)\n",
    "# -------------------------------------------\n",
    "# IMPORTANT: start from deep copies -> idempotent runs\n",
    "df_raw   = df_one.copy(deep=True)\n",
    "df_stage = df_raw.copy(deep=True)\n",
    "\n",
    "# 1) Build masks (only -1 and MAD-based jumps)\n",
    "gmask, pmasks = build_masks_only_neg1_and_jumps(\n",
    "    df_stage,\n",
    "    max_speed_px_per_frame=MAX_SPEED_PX_PER_FRAME,   # fallback\n",
    "    thresholds=auto_thresholds                       # <-- from previous cell\n",
    ")\n",
    "quick_mask_report(gmask, pmasks, thresholds=auto_thresholds)\n",
    "\n",
    "# 2) Apply masks ‚Üí set bad (x,y) to NaN (NEW df)\n",
    "df_stage = apply_masks(df_stage, gmask, pmasks)\n",
    "\n",
    "# 3) Interpolate short gaps ONLY (NEW df)\n",
    "df_stage = interpolate_short_gaps(df_stage, max_gap=MAX_SHORT_GAP, method=INTERP_METHOD)\n",
    "\n",
    "# 4) Optional light smoothing (NEW df)\n",
    "if APPLY_SMOOTHING:\n",
    "    df_stage = smooth_positions(df_stage, window=SMOOTH_WINDOW)\n",
    "\n",
    "df_clean = df_stage  # final cleaned dataframe\n",
    "\n",
    "# 5) Compare before/after\n",
    "print(\"\\n=== % NaNs BEFORE ===\")\n",
    "print(percent_nans(df_raw.where(df_raw >= 0)))\n",
    "print(\"\\n=== % NaNs AFTER  ===\")\n",
    "print(percent_nans(df_clean))\n",
    "\n",
    "print(\"\\n=== Speed summary BEFORE ===\")\n",
    "print(speed_summary(df_raw))\n",
    "print(\"\\n=== Speed summary AFTER  ===\")\n",
    "print(speed_summary(df_clean))\n",
    "\n",
    "# 6) Save cleaned H5 (overwrites deterministically)\n",
    "df_clean.to_hdf(H5_OUT, key=\"df_with_missing\", mode=\"w\")\n",
    "print(f\"\\n‚úÖ Saved cleaned file to: {H5_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d510c1d5",
   "metadata": {},
   "source": [
    "--- \n",
    "### Compare before / after cleaning\n",
    "\n",
    "After running the pre-processing pipeline, we print two key summaries:\n",
    "\n",
    "1. **% of NaN frames per body part**  \n",
    "   This tells us **how much of the trajectory was marked as invalid or interpolated**.  \n",
    "   - **Low NaN % (0‚Äì5%)** ‚Üí Excellent tracking; only a few missing or bad frames.  \n",
    "   - **Moderate NaN % (5‚Äì15%)** ‚Üí Normal for realistic data, often due to brief occlusions or lighting changes.  \n",
    "   - **High NaN % (>20%)** ‚Üí Something may be wrong ‚Äî the tracker struggled a lot, or parameters might be too strict.  \n",
    "   \n",
    "   üëâ *Think of NaN percentage as the ‚Äúdata confidence score‚Äù for each body part.*\n",
    "\n",
    "   If one part (e.g., tail tip) has a much higher NaN %, it might simply be harder to detect consistently; or your camera angle hides it often.\n",
    "\n",
    "\n",
    "2. **‚ö° Speed summary (median / p95 / max)**  \n",
    "   This describes the **distribution of movement speeds** for each body part.  \n",
    "   - **Median speed** ‚Üí Typical motion magnitude.  \n",
    "   - **95th percentile (p95)** ‚Üí Usual upper limit for realistic movements.  \n",
    "   - **Max speed** ‚Üí The largest observed jump; a good check for outliers.\n",
    "\n",
    "   After cleaning:\n",
    "   - NaN percentage usually decreases if you interpolate short gaps\n",
    "   - The **max** and **p95 speeds** should usually **drop** once spikes are masked and gaps are filled \n",
    "   - The **median speed**  often stays similar or decreases a bit. It can drop more when you both interpolate and smooth since straight fills and rolling filters reduce frame-to-frame jitter. A large drop in median is normal when many short gaps were interpolated or when smoothing is strong\n",
    "   - If all speeds drop drastically, you may have over-filtered (too aggressive thresholds or too much smoothing).\n",
    "\n",
    "---\n",
    "\n",
    "### üß† How to reason about your results\n",
    "\n",
    "Ask yourself:\n",
    "- Did the cleaning remove obvious outliers but keep natural motion?  \n",
    "- Are certain body parts more problematic (many NaNs or very high speeds)? Why might that be?  \n",
    "- Would adjusting the MAD `k` value (or interpolation length) change the balance between ‚Äúclean‚Äù and ‚Äúover-filtered‚Äù?\n",
    "\n",
    "\n",
    "> ‚úÖ **Goal:** After cleaning, the data should look smoother and more realistic\n",
    "> no ‚Äúteleportations,‚Äù no jitter, but still preserving the true dynamics of the animal‚Äôs behavior.\n",
    "\n",
    "\n",
    "**Summary of the Pose Cleaning Pipeline**\n",
    "\n",
    "| **Step** | **What happens** | **Why** |\n",
    "|-----------|------------------|--------------------|\n",
    "| **1. Auto thresholds (MAD rule)** | Compute each body part‚Äôs typical movement speed using the Median + *k* √ó MAD rule. | Each body part moves differently; this gives an adaptive limit for what counts as an unrealistic ‚Äújump.‚Äù |\n",
    "| **2. Mask bad frames** | Mark frames where likelihood = -1 or where the movement speed exceeds the threshold. | Flags missing or impossible detections to prevent them from affecting analysis. |\n",
    "| **3. Apply masks** | Replace bad frames with `NaN` (missing values). | Prepares the data for safe interpolation; no false coordinates remain. |\n",
    "| **4. Interpolate short gaps** | Fill small consecutive NaN gaps (e.g., ‚â§ 10 frames) using linear interpolation. | Maintains smooth continuity for short interruptions without inventing long motions. |\n",
    "| **5. Smooth positions** | Apply a short rolling median filter (e.g., 5 frames). | Removes pixel-level jitter while keeping real motion intact. |\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Reflection: One Possible Pre-Processing Pipeline\n",
    "\n",
    "The pipeline above is a **proposed and general approach** for cleaning pose-estimation data.  \n",
    "It works well for many experiments, but it is **not the only possible method**.\n",
    "\n",
    "Different laboratories, species, and recording setups often require **adjustments**:\n",
    "- Frame rates, lighting, or background noise can affect what counts as an outlier.  \n",
    "- Some projects prioritize **precision** (fewer interpolations), while others prioritize **continuity** (smoother trajectories).  \n",
    "- Advanced methods might include **Kalman filters**, **Gaussian process smoothing**, or even **model retraining** on difficult frames.\n",
    "\n",
    "There is no single ‚Äúbest‚Äù cleaning procedure; the right one depends on:\n",
    "- The **scientific question** (e.g., fine kinematics vs. coarse behavior).  \n",
    "- The **quality and type** of the recordings.  \n",
    "- The **tolerance for uncertainty** in motion tracking.\n",
    "\n",
    "\n",
    "> üó£Ô∏è *Think about how you would adapt this cleaning pipeline to your own data; what stays the same, and what would you change?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c58d90",
   "metadata": {},
   "source": [
    "## Supplementary . Spatial distributions\n",
    "\n",
    "### üéØ Likelihood Heatmap: Quick Explanation\n",
    "\n",
    "This function visualizes **where the tracker performs well or poorly** by plotting the **average likelihood** across space.\n",
    "\n",
    "`_discover_triplets(df)`\n",
    "\n",
    "Finds matching columns `*_x`, `*_y`, and `*_likelihood` for each bodypart (e.g. `nose_x`, `nose_y`, `nose_likelihood`).  \n",
    "‚û°Ô∏è Makes it easy to loop over all tracked points.\n",
    "\n",
    "\n",
    "üó∫Ô∏è `likelihood_heatmap(df_one, ...)`\n",
    "\n",
    "1. Collects all `(x, y, likelihood)` values (ignoring `-1` = missing).  \n",
    "2. Divides the image into a 2D grid (bins).  \n",
    "3. Computes the **mean likelihood per cell**.  \n",
    "4. Masks cells with too few samples (to avoid noise).  \n",
    "5. Displays a **heatmap** where:\n",
    "   - **Bright areas** ‚Üí reliable tracking  \n",
    "   - **Dark areas** ‚Üí frequent tracking loss  \n",
    "\n",
    "#### üí° Why it‚Äôs useful\n",
    "Helps detect **where in the arena the model struggles** (e.g., edges, reflections, shadows).  \n",
    "Use it to decide if you need more labels, better lighting, or camera calibration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _discover_triplets(df: pd.DataFrame) -> dict[str, tuple[str,str,str]]:\n",
    "    \"\"\"\n",
    "    Retourne un dict {prefix: (x_col, y_col, like_col)} en d√©tectant les triplets *_x, *_y, *_likelihood.\n",
    "    Compatible single/multi-animal (ex: 'animal0_nose_x').\n",
    "    \"\"\"\n",
    "    x_cols  = {m.group(1): col for col in df.columns if (m:=re.match(r\"(.+)_x$\", col))}\n",
    "    y_cols  = {m.group(1): col for col in df.columns if (m:=re.match(r\"(.+)_y$\", col))}\n",
    "    l_cols  = {m.group(1): col for col in df.columns if (m:=re.match(r\"(.+)_likelihood$\", col))}\n",
    "    prefixes = set(x_cols) & set(y_cols) & set(l_cols)\n",
    "    return {p: (x_cols[p], y_cols[p], l_cols[p]) for p in sorted(prefixes)}\n",
    "\n",
    "def likelihood_heatmap(\n",
    "    df_one: pd.DataFrame,\n",
    "    bodyparts: list[str] | None = None,\n",
    "    bins: int | tuple[int,int] = 60,\n",
    "    extent: tuple[float,float,float,float] | None = None,\n",
    "    min_count_per_bin: int = 5,\n",
    "    title: str = \"Mean likelihood heatmap\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Affiche une heatmap de la *moyenne du likelihood* par position (x,y).\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    bodyparts : liste optionnelle des 'prefixes' √† inclure (ex: ['nose', 'animal0_nose']).\n",
    "                Par d√©faut, utilise tous les triplets trouv√©s.\n",
    "    bins      : nb de bacs (int) ou (nx, ny) pour histogramme 2D.\n",
    "    extent    : (xmin, xmax, ymin, ymax) pour fixer les limites. Par d√©faut, auto depuis les donn√©es.\n",
    "    min_count_per_bin : masque les bacs trop peu peupl√©s (< ce seuil).\n",
    "    \"\"\"\n",
    "    triplets = _discover_triplets(df_one)\n",
    "    if not triplets:\n",
    "        raise ValueError(\"Aucun triplet *_x, *_y, *_likelihood* d√©tect√©.\")\n",
    "\n",
    "    if bodyparts is not None:\n",
    "        missing = [bp for bp in bodyparts if bp not in triplets]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Bodyparts inconnus: {missing}\\nDisponibles: {list(triplets.keys())}\")\n",
    "        use = {bp: triplets[bp] for bp in bodyparts}\n",
    "    else:\n",
    "        use = triplets\n",
    "\n",
    "    # Concat√©ner toutes les positions & likelihood s√©lectionn√©es\n",
    "    xs, ys, ls = [], [], []\n",
    "    for (x_col, y_col, l_col) in use.values():\n",
    "        x = df_one[x_col].to_numpy(dtype=float, copy=False)\n",
    "        y = df_one[y_col].to_numpy(dtype=float, copy=False)\n",
    "        L = df_one[l_col].to_numpy(dtype=float, copy=False)\n",
    "\n",
    "        # Remplacer sentinelles -1 par NaN\n",
    "        x[x < 0] = np.nan\n",
    "        y[y < 0] = np.nan\n",
    "        L[L < 0] = np.nan  # SuperModel peut mettre -1 en likelihood\n",
    "\n",
    "        # Garder uniquement les points valides (x,y,l non-NaN)\n",
    "        valid = (~np.isnan(x)) & (~np.isnan(y)) & (~np.isnan(L))\n",
    "        xs.append(x[valid]); ys.append(y[valid]); ls.append(L[valid])\n",
    "\n",
    "    if not xs:\n",
    "        raise ValueError(\"Aucune donn√©e valide apr√®s nettoyage.\")\n",
    "    X = np.concatenate(xs)\n",
    "    Y = np.concatenate(ys)\n",
    "    W = np.concatenate(ls)\n",
    "\n",
    "    # D√©finir l'√©tendue automatiquement si non fournie\n",
    "    if extent is None:\n",
    "        xmin, xmax = np.nanpercentile(X, [1, 99])\n",
    "        ymin, ymax = np.nanpercentile(Y, [1, 99])\n",
    "        # petite marge\n",
    "        dx = (xmax - xmin) * 0.05\n",
    "        dy = (ymax - ymin) * 0.05\n",
    "        extent = (xmin - dx, xmax + dx, ymin - dy, ymax + dy)\n",
    "\n",
    "    # Histogrammes 2D: somme des likelihoods et compte d'√©chantillons\n",
    "    H_sum, xedges, yedges = np.histogram2d(X, Y, bins=bins, range=[[extent[0], extent[1]], [extent[2], extent[3]]], weights=W)\n",
    "    H_cnt, _,     _      = np.histogram2d(X, Y, bins=[xedges, yedges])\n",
    "\n",
    "    # Moyenne du likelihood par bin\n",
    "    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "        H_mean = H_sum / H_cnt\n",
    "\n",
    "    # Masquer bacs trop vides\n",
    "    H_mean_masked = np.where(H_cnt >= max(1, min_count_per_bin), H_mean, np.nan)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(6.5, 5.5))\n",
    "    im = ax.imshow(\n",
    "        H_mean_masked.T,\n",
    "        origin=\"lower\",\n",
    "        extent=extent,\n",
    "        aspect=\"equal\",\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"Mean likelihood\")\n",
    "\n",
    "    ax.set_xlabel(\"x (px)\")\n",
    "    ax.set_ylabel(\"y (px)\")\n",
    "    ax.set_title(title + (\"\" if bodyparts is None else f\" ‚Äî {', '.join(use.keys())}\"))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"fig\": fig, \"ax\": ax,\n",
    "        \"H_mean\": H_mean, \"H_count\": H_cnt,\n",
    "        \"xedges\": xedges, \"yedges\": yedges, \"extent\": extent\n",
    "    }\n",
    "\n",
    "# --- Exemples d'utilisation ---\n",
    "# 1) Heatmap globale (tous les bodyparts disponibles)\n",
    "likelihood_heatmap(df_one)\n",
    "\n",
    "# 2) Focaliser sur un bodypart (selon vos colonnes, ex: 'animal0_nose' ou juste 'nose')\n",
    "likelihood_heatmap(df_one, bodyparts=['nose'])\n",
    "\n",
    "# 3) Grille plus fine et seuil de comptage plus strict\n",
    "likelihood_heatmap(df_one, bins=100, min_count_per_bin=10, title=\"Likelihood (dense bins)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose2behav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
