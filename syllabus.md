# Syllabus




## Course overview 

This course introduces students to quantitative, data-driven methods for analyzing animal behavior from video recordings. Using deep-learning based pose estimation tools such as *DeepLabCut*, participants learn how to extract movement keypoints and transform them into interpretable behavioral metrics. The course combines lectures on the theoretical foundations of computational behavioral analysis with hands-on exercises that guide students through the full workflow: from video â†’ pose data â†’ behavioral quantification â†’ visualization and interpretation.

## In practice

This course combines theoretical sessions (short presentations, sometimes followed by quizzes) with hands-on laboratory exercises (â€œLabsâ€) for each major theme.
The labs are designed to help you apply theoretical concepts to real-world data and examples in animal pose estimation and behavioral analysis.

Throughout the course, you will find:

- Conceptual questions that help you consolidate what was covered during the lectures.
- Practical exercises (Labs) in Jupyter Notebooks where you will manipulate real data.
- Challenging reflection questions, which encourage deeper thinking and may or may not appear in the quizzes.

You have access to this **Book**, which contains:

- Introductory information and guidance for each Lab. --> Start with [Lab 0](labs/0_prerequisites)
- Direct links at the end of each lab to the corresponding Jupyter Notebooks where you will perform the exercises. In the case where there are no links, they will be provided by your instructor the day of the course.

Depending on your specific program or module, you may be required to complete all labs or only a subset of them.

## What Are the Labs?

The Labs form the practical component of this course.
Each lab focuses on a key topic related to animal pose estimation and behavioral analysis using AI-based tools such as DeepLabCut.

## ğŸ¯Course learning outcomes

By the end of the course, students will be able to:

* Explain the principles of pose estimation.
* Preprocess and clean pose data generated from videos.
* Compute basic behavioral metrics such as trajectories, speed, and spatial occupancy.
* Visualize and interpret behavioral data to generate clear scientific insights.
* Critically evaluate the strengths and limitations of AI-driven pose estimation analysis approaches.

## ğŸ‘©â€ğŸ« Instructors

â­ï¸ [S. Lizbeth MondragÃ³n-GonzÃ¡lez](https://lizbeth-mg.me/): Course lead, Ph.D. Research Engineer, Paris Brain Institute.

â­ï¸ **Indira Lavocat**: Assistant, Engineer at the Paris Brain Insitute.