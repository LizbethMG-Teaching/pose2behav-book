# Syllabus

## Course overview 

This course introduces students to quantitative, data-driven methods for analyzing animal behavior from video recordings. Using deep-learning based pose estimation tools such as *DeepLabCut*, participants learn how to extract movement keypoints and transform them into interpretable behavioral metrics. The course combines lectures on the theoretical foundations of computational behavioral analysis with hands-on exercises that guide students through the full workflow: from video → pose data → behavioral quantification → visualization and interpretation.


## 🎯Course leanring outcomes
By the end of the course, students will be able to:

* Explain the principles of pose estimation.
* Preprocess and clean pose data generated from videos.
* Compute basic behavioral metrics such as trajectories, speed, spatial occupancy, and turning bias.
* Segment activity states and construct ethograms from video data.
* Visualize and interpret behavioral data to generate clear scientific insights.
* Understand the principles behind behavioral segmentation techniques and apply them to real data.
* Critically evaluate the strengths and limitations of AI-driven behavioral analysis approaches.

## 👩‍🏫 Instructors


* **S. Lizbeth Mondragón-González**  – Course lead, Ph.D. Research Engineer, Paris Brain Institute.

* **Christiane Schreiweiss** - Lecturer, Ph.D. Professor at Université Lyon 1

* **Indira Lavocat** - Assistant, Engineer at the Paris Brain Insitut.

